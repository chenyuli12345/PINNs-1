{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下面这行代码，是为了把自己编写的代码文件当作一共模块导入，这里是把Utilities文件夹中的plotting.py文件当作python的模块导入，对应的是下面的from plotting import newfig, savefig。路径要随着不同设备的系统做相应的修改\n",
    "import sys #导入sys模块。sys模块提供了一些变量和函数，用于与 Python解释器进行交互和访问。例如，sys.path 是一个 Python 在导入模块时会查找的路径列表，sys.argv 是一个包含命令行参数的列表，sys.exit() 函数可以用于退出 Python 程序。导入 sys 模块后，你就可以在你的程序中使用这些变量和函数了。\n",
    "sys.path.insert(0, '../../../Utilities/') #在 Python的sys.path列表中插入一个新的路径。sys.path是一个 Python 在导入模块时会查找的路径列表。新的路径'../../Utilities/'相对于当前脚本的路径。当你尝试导入一个模块时，Python 会在 sys.path 列表中的路径下查找这个模块。通过在列表开始位置插入一个路径，你可以让 Python 优先在这个路径下查找模块。这在你需要导入自定义模块或者不在 Python 标准库中的模块时非常有用。\n",
    "\n",
    "import torch\n",
    "#collections是python一个内置模块，提供了一些有用的数据结构\n",
    "from collections import OrderedDict  #这个类是字典dict的一个子类，用于创建有序的字典。普通字典中元素顺序是无序的，在OrderedDict中元素的顺序是有序的，元素的顺序是按照它们被添加到字典中的顺序决定的。\n",
    "\n",
    "from pyDOE import lhs #`pyDOE`是一个Python库，用于设计实验。它提供了一些函数来生成各种设计，如因子设计、拉丁超立方设计等。`lhs`是库中的一个函数，全名为\"Latin Hypercube Sampling\"，拉丁超立方采样。这是一种统计方法，用于生成一个近似均匀分布的多维样本点集。它在参数空间中生成一个非常均匀的样本，这对于高维数值优化问题非常有用，因为它可以更好地覆盖参数空间。\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io #导入了scipy库中的io模块。scipy.io模块包含了一些用于文件输入/输出的函数，例如读取和写入.mat文件（MATLAB格式）\n",
    "from scipy.interpolate import griddata #`scipy.interpolate`是`scipy`库中的一个模块，提供了许多插值工具，用于在给定的离散数据点之间进行插值和拟合。`griddata`是这个模块中的一个函数，用于在无规则的数据点上进行插值。\n",
    "\n",
    "import random\n",
    "\n",
    "import skopt #用于优化问题的库，特别是机器学习中的超参数优化\n",
    "from distutils.version import LooseVersion #distutils是Python的一个标准库，用于构建和安装Python包。LooseVersion是一个类，用于比较版本号\n",
    "\n",
    "\n",
    "from plotting_torch import newfig, savefig #从自定义的plotting_torch.py文件中导入了newfig和savefig函数。这两个函数用于创建和保存图形。这两个函数的定义在plotting_torch.py文件中\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable #`mpl_toolkits.axes_grid1`是`matplotlib`库的一个模块，提供了一些高级的工具来控制matplotlib图形中的坐标轴和颜色条。`make_axes_locatable`是模块中的一个函数，用于创建一个可分割的坐标轴。可以在这个坐标轴的四个方向（上、下、左、右）添加新的坐标轴或颜色条。\n",
    "import matplotlib.gridspec as gridspec #是`matplotlib`库的一个模块，用于创建一个网格布局来放置子图。在`matplotlib`中可以创建一个或多个子图（subplot），每个子图都有自己的坐标轴，并可以在其中绘制图形。`gridspec`模块提供了一个灵活的方式来创建和放置子图。\n",
    "import time #一个内置模块，用于处理时间相关的操作。\n",
    "\n",
    "\n",
    "from tqdm import tqdm #一个快速，可扩展的python进度条库，可以在python长循环中添加一个进度提示信息，用户只需要封装任意的迭代器tqdm(iterator)。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs:  3\n",
      "GPU 0: NVIDIA GeForce RTX 2080 Ti, Allocated: 70894592, Reserved: 295698432\n",
      "GPU 1: NVIDIA GeForce RTX 2080 Ti, Allocated: 0, Reserved: 0\n",
      "GPU 2: NVIDIA GeForce RTX 2080 Ti, Allocated: 0, Reserved: 0\n"
     ]
    }
   ],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "print('Number of available GPUs: ', num_gpus)\n",
    "\n",
    "for i in range(num_gpus):\n",
    "    torch.cuda.set_device(i)\n",
    "    allocated = torch.cuda.memory_allocated()\n",
    "    reserved = torch.cuda.memory_reserved()\n",
    "    print('GPU {}: {}, Allocated: {}, Reserved: {}'.format(i, torch.cuda.get_device_name(i), allocated, reserved))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0) #设置当前使用的GPU设备。这里设置为1号GPU设备（第二块显卡）。\n",
    "\n",
    "# CUDA support \n",
    "\n",
    "#设置pytorch的设备，代表了在哪里执行张量积算，设备可以是cpu或者cuda（gpu），并将这个做运算的设备对象存储在变量device中，后续张量计算回在这个设备上执行\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class DNN(torch.nn.Module):\n",
    "    #第一个方法\n",
    "    def __init__(self, layers):\n",
    "        super(DNN, self).__init__() #调用父类的__init__方法进行初始化\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1 #定义名为depth的属性，表示神经网络的深度，等于层数-1\n",
    "        \n",
    "        # set up layer order dict\n",
    "        self.activation = torch.nn.Tanh #设置激活函数为tanh\n",
    "         \n",
    "        layer_list = list() #定义一个空列表layer_list\n",
    "        for i in range(self.depth - 1):  #循环depth次\n",
    "            #将每一层（全连接层）添加到layer_list中\n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            #将每一层的激活函数添加到layer_list中\n",
    "            layer_list.append(('activation_%d' % i, self.activation()))\n",
    "\n",
    "        #循环结束后，将最后一层的线性变换添加到layer_list中（因为没有激活函数了）\n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        #然后使用OrderedDict将layer_list中的元素转换为有序字典\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers，将layerDict转换为一个神经网络模型，赋值给self.layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "    \n",
    "    #第二个方法，定义了模型的前向传播过程\n",
    "    def forward(self, x):  #接收输入x\n",
    "        out = self.layers(x) #将输入x传入神经网络模型self.layers中，得到输出out\n",
    "        return out #返回输出out\n",
    "    \n",
    "    # 新增方法，获取最后一个隐藏层的输出\n",
    "    def hidden_output(self, x):\n",
    "        # 遍历每一层，直到最后一个隐藏层\n",
    "        for i in range(self.depth - 1):\n",
    "            # 获取当前层的线性变换\n",
    "            x = self.layers[i*2](x)\n",
    "            # 获取当前层的激活函数\n",
    "            x = self.layers[i*2 + 1](x)\n",
    "        # 返回最后一个隐藏层的输出\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the physics-guided neural network\n",
    "class PhysicsInformedNN():\n",
    "    # Initialize the class\n",
    "    def __init__(self, X_u, u, X_f, layers, lb, ub, nu, X_star, u_star): #这个类包含的第一个方法__init__，这是一个特殊的方法，也就是这个类的构造函数，用于初始化新创建的对象，接受了几个参数\n",
    "\n",
    "        \n",
    "        # boundary conditions\n",
    "        #将传入的lb和ub参数的值存储在实例中，以便后续使用。这样可以在类的其他方法中通过self.lb和self.ub来访问这些值。\n",
    "        self.lb = torch.tensor(lb).float().to(device) #创建一个pytorch张量（数据来源于lb），并将其转换为浮点类型，最后将张量移动到指定的设备上\n",
    "        self.ub = torch.tensor(ub).float().to(device)\n",
    "        \n",
    "        # data\n",
    "        #创建四个pytorch张良，将X_u的第一列赋值给self.x_u，将X_u的第二列赋值给self.t_u。转换为浮点类型，移动到指定设备上，并且这几个张量都需要计算梯度\n",
    "        self.x_u = torch.tensor(X_u[:, 0:1], requires_grad=True).float().to(device)\n",
    "        self.t_u = torch.tensor(X_u[:, 1:2], requires_grad=True).float().to(device)\n",
    "        self.x_f = torch.tensor(X_f[:, 0:1], requires_grad=True).float().to(device)\n",
    "        self.t_f = torch.tensor(X_f[:, 1:2], requires_grad=True).float().to(device)\n",
    "\n",
    "        self.x_star = torch.tensor(X_star[:, 0:1], requires_grad=True).float().to(device)\n",
    "        self.t_star = torch.tensor(X_star[:, 1:2], requires_grad=True).float().to(device)\n",
    "\n",
    "        \n",
    "        self.u = torch.tensor(u).float().to(device)\n",
    "        self.u_star = torch.tensor(u_star).float().to(device)\n",
    "        \n",
    "        self.layers = layers\n",
    "        self.nu = nu\n",
    "        \n",
    "        # deep neural networks\n",
    "        self.dnn = DNN(layers).to(device) #创建一个DNN类的实例，传入layers参数来实现神经网络的初始化，然后将这个实例移动到指定的设备上\n",
    "        \n",
    "        # optimizers: using the same settings\n",
    "        #创建优化器optimizer，使用LBFGS算法，具体每个参数意义见下方\n",
    "        self.optimizer_LBFGS = torch.optim.LBFGS(\n",
    "            self.dnn.parameters(), #要优化的参数，这里返回的是一个生成器，包含了self.dnn中的所有参数（神经网络权重与偏置）\n",
    "            lr=1.0,  #学习率设置为1\n",
    "            max_iter=50000,  #最大迭代次数为50000\n",
    "            max_eval=50000,  #最大评估次数为50000\n",
    "            history_size=50, #历史大小为50，即用于计算Hessian矩阵近似的最近几步的信息\n",
    "            # tolerance_grad=1e-10,  #优化的第一个停止条件，当梯度的L2范数小于1e-5时停止优化\n",
    "            # tolerance_change=1.0 * np.finfo(float).eps, #优化的第二个停止条件，当优化的目标函数值的变化小于1.0 * np.finfo(float).eps时停止优化\n",
    "            line_search_fn=\"strong_wolfe\"       # 制定了用于一维搜索的方法，这里表示用强Wolfe条件\n",
    "        )\n",
    "\n",
    "        #创建第二个优化器，括号内为要优化的参数，使用Adam优化方法\n",
    "        self.optimizer_Adam = torch.optim.Adam(self.dnn.parameters())\n",
    "\n",
    "        #创建第三个优化器，括号内为要优化的参数，使用SGD优化方法\n",
    "        self.optimizer_SGD = torch.optim.SGD(self.dnn.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "        self.iter = 0 #记录迭代次数 \n",
    "\n",
    "        self.loss_value = [] #创建一个空列表，用于存储损失值\n",
    "\n",
    "        self.test_error = [] #创建一个空列表，用于存储测试误差\n",
    "        \n",
    "    #定义了一个名为net_u的函数/方法，用于计算神经网络的输出。这个方法接受两个参数，分别是x和t，其中x是输入数据，t是时间数据。最后返回神经网络的输出。     \n",
    "    def net_u(self, x, t):  \n",
    "        u = self.dnn(torch.cat([x, t], dim=1))  #（第一个参数将输入的两个参数x和t在第二个维度（列）上进行拼接，形成一个新的张量）调用DNN，根据两个参数权重和偏置，以及新得到的张量，计算神经网络的输出u\n",
    "        return u\n",
    "    \n",
    "    #定义了一个名为net_f的函数/方法，用于计算论文中的f。这个方法接受两个参数，分别是x和t，其中x是输入数据，t是时间数据。最后返回计算得到的f。\n",
    "    def net_f(self, x, t):\n",
    "        \"\"\" The pytorch autograd version of calculating residual \"\"\"\n",
    "        u = self.net_u(x, t) #调用上面的net_u函数，计算神经网络的输出u\n",
    "        \n",
    "        #计算u关于t的梯度，也就是u关于t的导数，这里使用了pytorch的自动求导功能\n",
    "        u_t = torch.autograd.grad(\n",
    "            u, t,  #输入的张量，要计算u关于t的导数\n",
    "            grad_outputs=torch.ones_like(u), #生成一个与u形状相同，所有元素均为1的张量，这个参数用于指定向量-雅可比积的像两部分\n",
    "            retain_graph=True, #表示计算完梯度之后保留计算图若需要多次计算梯度，则需要设置改参数为True\n",
    "            create_graph=True #创建梯度的计算图，使我们能够计算高阶导数\n",
    "        )[0] #这个函数的返回值是一个元组，其中包含了每个输入张量的梯度。这里只关心第一个输入张量u的梯度，所以我们使用[0]来获取这个梯度。？？？？又说只有一个梯度\n",
    "        u_x = torch.autograd.grad(\n",
    "            u, x, \n",
    "            grad_outputs=torch.ones_like(u),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        u_xx = torch.autograd.grad(\n",
    "            u_x, x, \n",
    "            grad_outputs=torch.ones_like(u_x),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        f = u_t + u * u_x - self.nu * u_xx #计算f，定义见论文\n",
    "        return f\n",
    "    \n",
    "    def loss_func(self):\n",
    "        self.optimizer_LBFGS.zero_grad() #清除之前计算的梯度（在PyTorch中，梯度会累积，所以在每次新的优化迭代之前，我们需要清除之前的梯度）\n",
    "        \n",
    "        u_pred = self.net_u(self.x_u, self.t_u) #调用之前定义的函数，传入参数得到神经网络的输出u\n",
    "        f_pred = self.net_f(self.x_f, self.t_f) #调用之前定义的函数，传入参数计算得到f\n",
    "        loss_u = torch.mean((self.u - u_pred) ** 2) #计算loss_u，定义见论文\n",
    "        loss_f = torch.mean(f_pred ** 2) #计算loss_f，定义见论文\n",
    "        \n",
    "        loss = loss_u + loss_f #计算总的loss\n",
    "        \n",
    "        loss.backward() #被调用以计算损失函数关于神经网络参数的梯度。这个梯度将被用于优化器来更新神经网络参数\n",
    "        self.iter += 1 #每调用一次损失函数，迭代次数加1\n",
    "\n",
    "        #record the loss value\n",
    "        self.loss_value.append(loss) #将计算得到的loss值添加到self.loss_value列表中\n",
    "\n",
    "        #record the test error\n",
    "        with torch.no_grad():\n",
    "            u_real_pred = self.net_u(self.x_star, self.t_star) #调用之前定义的函数，传入参数得到神经网络的输出u\n",
    "\n",
    "        error_test = torch.norm(self.u_star-u_real_pred,2)/torch.norm(self.u_star,2)\n",
    "\n",
    "        self.test_error.append(error_test)\n",
    "        return loss\n",
    "      \n",
    "    \n",
    "    def train(self, nIter, nIterLBFGS):\n",
    "        self.dnn.train() #将神经网络设置为训练模式而不是评估模式\n",
    "\n",
    "\n",
    "        # 初始化一个列表来存储每个epoch的权重矩阵\n",
    "        self.weights = []   \n",
    "\n",
    "\n",
    "        # #使用SGD优化器优化nIter次\n",
    "        # for epoch in tqdm(range(nIter), desc='SGD'):\n",
    "        #     u_pred = self.net_u(self.x_u, self.t_u)\n",
    "        #     f_pred = self.net_f(self.x_f, self.t_f)\n",
    "        #     loss = torch.mean((self.u - u_pred) ** 2) + torch.mean(f_pred ** 2)\n",
    "\n",
    "        #     # Backward and optimize\n",
    "        #     self.optimizer_SGD.zero_grad()\n",
    "        #     loss.backward()\n",
    "        #     self.optimizer_SGD.step()\n",
    "\n",
    "        #     #record the loss value\n",
    "        #     self.loss_value.append(loss)\n",
    "\n",
    "        #     # record the test error\n",
    "        #     with torch.no_grad():\n",
    "        #         u_real_pred = self.net_u(self.x_star, self.t_star) #调用之前定义的函数，传入参数得到神经网络的输出u\n",
    "\n",
    "        #     error_test = torch.norm(self.u_star-u_real_pred,2)/torch.norm(self.u_star,2)\n",
    "\n",
    "        #     self.test_error.append(error_test)\n",
    "\n",
    "\n",
    "        #     # 记录每一层的权重矩阵\n",
    "        #     epoch_weights = []\n",
    "        #     for layer in self.dnn.layers:\n",
    "        #         if isinstance(layer, torch.nn.Linear):  # 检查是否为全连接层\n",
    "        #             epoch_weights.append(layer.weight.data.clone())  # 使用.clone()来获取权重的副本\n",
    "        #     self.weights.append(epoch_weights)\n",
    "\n",
    "        #     W = self.weights\n",
    "\n",
    "\n",
    "\n",
    "        #使用Adam优化器优化nIter次\n",
    "        for epoch in tqdm(range(nIter), desc='Adam'):\n",
    "            u_pred = self.net_u(self.x_u, self.t_u) #调用之前定义的函数，传入参数得到神经网络的输出u\n",
    "            f_pred = self.net_f(self.x_f, self.t_f) #调用之前定义的函数，传入参数计算得到f\n",
    "            loss = torch.mean((self.u - u_pred) ** 2) + torch.mean(f_pred ** 2) #计算损失函数\n",
    "            \n",
    "            # Backward and optimize\n",
    "            self.optimizer_Adam.zero_grad() #清除该优化器之前计算的梯度（在PyTorch中，梯度会累积，所以在每次新的优化迭代之前，我们需要清除之前的梯度）\n",
    "            loss.backward() #被调用以计算损失函数关于神经网络参数的梯度。这个梯度将被用于优化器来更新神经网络参数\n",
    "            self.optimizer_Adam.step()  #使用之前的优化器self.optimizer_Adam，调用step方法(执行一步优化算法)，传入损失函数self.loss_func，进行优化\n",
    "            \n",
    "            #record the loss value\n",
    "            self.loss_value.append(loss) #将计算得到的loss值添加到self.loss_value列表中\n",
    "\n",
    "            # record the test error\n",
    "            with torch.no_grad():\n",
    "                u_real_pred = self.net_u(self.x_star, self.t_star) #调用之前定义的函数，传入参数得到神经网络的输出u\n",
    "            # batch_size = 100  # 设置批次大小\n",
    "            # n = len(self.x_star)\n",
    "            # u_real_pred = []\n",
    "            # for i in range(0, n, batch_size):\n",
    "            #     x_star_batch = self.x_star[i:i+batch_size]\n",
    "            #     t_star_batch = self.t_star[i:i+batch_size]\n",
    "            #     u_real_pred_batch = self.net_u(x_star_batch, t_star_batch)\n",
    "            #     u_real_pred.append(u_real_pred_batch)\n",
    "            # u_real_pred = torch.cat(u_real_pred)\n",
    "\n",
    "\n",
    "            error_test = torch.norm(self.u_star-u_real_pred,2)/torch.norm(self.u_star,2)\n",
    "\n",
    "            self.test_error.append(error_test)\n",
    "\n",
    "            # 记录每一层的权重矩阵\n",
    "            epoch_weights = []\n",
    "            for layer in self.dnn.layers:\n",
    "                if isinstance(layer, torch.nn.Linear):  # 检查是否为全连接层\n",
    "                    epoch_weights.append(layer.weight.data.clone())  # 使用.clone()来获取权重的副本\n",
    "            self.weights.append(epoch_weights)\n",
    "\n",
    "            W = self.weights\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "        #使用LBFGS优化器进一步，注意这里虽然迭代了500次，但其实使用LBFGS优化器优化的次数不止500次\n",
    "        for i in tqdm(range(nIterLBFGS), desc='LBFGS'):\n",
    "            self.optimizer_LBFGS.step(self.loss_func) #使用之前的优化器self.optimizer，调用step方法(执行一步优化算法)，传入损失函数self.loss_func，进行优化\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        x = torch.tensor(X[:, 0:1], requires_grad=True).float().to(device) #从输入中得到x和t（第一列和第二列），是张量，需要计算梯度，转换为浮点数类型，并将张量移动到指定设备上\n",
    "        t = torch.tensor(X[:, 1:2], requires_grad=True).float().to(device)\n",
    "\n",
    "        self.dnn.eval() #将神经网络切换为评估模式\n",
    "        u = self.net_u(x, t) #调用之前定义的函数得到神经网络的输出u,以及f\n",
    "        f = self.net_f(x, t)\n",
    "        u = u.detach().cpu().numpy() #将张量u和f先从计算图中分离出来，然后转换为numpy数组，最后将这个数组移动到cpu上\n",
    "        f = f.detach().cpu().numpy()\n",
    "        return u, f\n",
    "    \n",
    "\n",
    "    def hidden_predict(self, x,t):\n",
    "        x = torch.tensor(x, requires_grad=True).float().to(device) #从输入中得到x和t（第一列和第二列），是张量，需要计算梯度，转换为浮点数类型，并将张量移动到指定设备上\n",
    "        t = torch.tensor(t, requires_grad=True).float().to(device)\n",
    "        self.dnn.eval()\n",
    "        hidden_output = self.dnn.hidden_output(torch.cat([x, t], dim=1))\n",
    "        hidden_output_x = hidden_output[:, 0]\n",
    "        hidden_output_t = hidden_output[:, 1]\n",
    "        hidden_output_x = hidden_output_x.detach().cpu().numpy()\n",
    "        hidden_output_t = hidden_output_t.detach().cpu().numpy()\n",
    "        return hidden_output_x, hidden_output_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义采样函数，目的是采用sampler方法，生成n_samples个在指定空间内的准随机样本，这里space为二维的，因此每个样本都是一个二维点，即n_samples*2的数据点\n",
    "\n",
    "#共有6种采样器，分别是LHS、Halton、Hammersley、Sobol、Grid和Random，均为均匀采样方法\n",
    "\n",
    "def caiyang(n_samples, sampler): #接受两个参数，n_samples是样本数量，sampler是采样器名称，是一个字符串\n",
    "    space = [(-1.0, 1.0), (0.0, 1.0)] #指定样本生成的空间，一个二维空间，第一个维度是-1到1，第二个维度是0到1\n",
    "\n",
    "    #根据sampler的不同，选择不同的采样器，返回的sampler是一个采样器对象\n",
    "    if sampler == \"LHS\": #如果采样器是LHS（拉丁超采样，每个维度都被均匀划分为等量区间，每个样本都是从每个维度的一个区间中随机选取的）\n",
    "        sampler = skopt.sampler.Lhs(lhs_type=\"centered\", criterion=\"maximin\", iterations=1000) #第一个参数表示如何从每个区间选取样本，这里表示从每个区间的中心选取样本；第二个参数表示如何划分区间，这里表示尽可能使样本之间的最小距离最大；第三个表示通过优化过程得到样本量的迭代次数（即会尝试1000种不同的样本配置，并最终选择质量最好的那个）\n",
    "    elif sampler == \"Halton\": #Halton序列是一种低差异序列，用于在高维空间中生成点\n",
    "        sampler = skopt.sampler.Halton(min_skip=-1, max_skip=-1)  #两个参数用于控制序列的起始点，Halton序列可以通过跳过序列的前几个点来改变序列的七十点。两个参数分别制定了跳过点的最小和最大数量，这里-1表示不跳过任何点\n",
    "    elif sampler == \"Hammersley\": #Hammersley序列是一种低差异序列，用于在高维空间中生成点\n",
    "        sampler = skopt.sampler.Hammersly(min_skip=-1, max_skip=-1) #两个参数用于控制序列的起始点，Hammersley序列可以通过跳过序列的前几个点来改变序列的七十点。两个参数分别制定了跳过点的最小和最大数量，这里-1表示不跳过任何点\n",
    "    elif sampler == \"Sobol\":\n",
    "        # Remove the first point [0, 0, ...] and the second point [0.5, 0.5, ...], which are too special and may cause some error.\n",
    "        # Sobol采样器的实现有一个问题，即生成的前两个样本点通常不是随机的而是固定的，Sobol序列的前两个点（[0, 0, ...]和[0.5, 0.5, ...]）在许多情况下都被认为是“特殊”的点，可能会对某些计算产生不利影响。因此设置跳过前两个点，而且skopt库在0.9版本号取消了max/min_skip参数，所以需要根据skopt的版本号来选择不同的参数\n",
    "        if LooseVersion(skopt.__version__) < LooseVersion(\"0.9\"): #先检查skopt的版本是否大于0.9,若小于\n",
    "            sampler = skopt.sampler.Sobol(min_skip=2, max_skip=2, randomize=False) #则使用Sobol采样器，min_skip和max_skip表示跳过的点的数量，这里表示跳过前两个点，randomize表示是否随机化\n",
    "        else: #若skopt的版本大于0.9\n",
    "            sampler = skopt.sampler.Sobol(skip=0, randomize=False) #则使用Sobol采样器，skip表示跳过的点的数量，这里表示不跳过任何点，randomize表示是否随机化 \n",
    "            return np.array(sampler.generate(space, n_samples + 2)[2:]) #生成n_samples+2个样本，然后返回除了前两个样本之外的所有样本，也就是返回n_samples个样本，每个样本都是一个二维点，且范围在指定的空间space里面\n",
    "    elif sampler == \"Grid\":\n",
    "        x_min, x_max = space[0]\n",
    "        t_min, t_max = space[1]\n",
    "        \n",
    "        # 计算每个维度的网格大小\n",
    "        x_grid_size = (x_max - x_min) / (n_samples // int(np.sqrt(n_samples)) - 1) # x维度上（纵轴），每行有10个点\n",
    "        t_grid_size = (t_max - t_min) / int(np.sqrt(n_samples))  # \n",
    "        \n",
    "        # 生成等距均匀网格采样点\n",
    "        samples = []\n",
    "        for i in range(n_samples // int(np.sqrt(n_samples))):\n",
    "            for j in range(int(np.sqrt(n_samples))):\n",
    "                # 计算每个网格单元的中心点\n",
    "                x = x_min + i * x_grid_size\n",
    "                t = t_min + j * t_grid_size\n",
    "                samples.append([t, x])\n",
    "        \n",
    "        return np.array(samples)\n",
    "    \n",
    "    elif sampler == \"Random\":\n",
    "        # 从space中提取出x_min, x_max, t_min, t_max\n",
    "        x_min, x_max = space[0]\n",
    "        t_min, t_max = space[1]\n",
    "\n",
    "        # 生成x和t的随机数\n",
    "        x = np.random.rand(n_samples, 1) * (x_max - x_min) + x_min\n",
    "        t = np.random.rand(n_samples, 1) * (t_max - t_min) + t_min\n",
    "\n",
    "        # 将x和t合并为一个(n_samples, 2)的数组\n",
    "        samples = np.hstack((t, x))\n",
    "        return samples #生成一个形状为(n_samples, 2)的随机数组\n",
    "\n",
    "\n",
    "\n",
    "    return np.array(sampler.generate(space, n_samples)) #生成n_samples个样本，每个样本都是一个二维点，且范围在指定的空间space里面（n_samples*2）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义设置随机数种子的函数，第一个参数seed表示种子；第二个参数用来设置CUDA的卷积操作是否确定性，默认为False，表示没有确定性\n",
    "def set_seed(seed, deterministic=False):\n",
    "    torch.manual_seed(seed) #设置pytorch的CPU随机数生成器的种子\n",
    "    torch.cuda.manual_seed_all(seed) #设置putorch的所有GPU随机数生成器的种子\n",
    "    np.random.seed(seed) #设置numpy的随机数生成器的种子\n",
    "    random.seed(seed) #设置python的内置随机数生成器的种子\n",
    "    torch.backends.cudnn.deterministic = deterministic #True会让CUDA的卷积操作变得确定性，即对于相同的输入，每次运行会得到相同的结果，False则相反"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.88it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 33.20it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.68it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.58it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.15it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.00it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 33.14it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 33.07it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 33.79it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 33.17it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.55it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.98it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 33.13it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 33.08it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.88it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.39it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.82it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.26it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.60it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.87it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.38it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.73it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.40it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.70it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.02it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.05it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.91it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.36it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.07it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.71it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.61it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.22it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.26it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.31it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.32it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.84it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.47it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 33.03it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.57it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.41it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.19it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:19<00:00, 26.15it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.89it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.88it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.65it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.06it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.68it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.30it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.54it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.19it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.19it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.89it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.86it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.45it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.26it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.10it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.92it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.99it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.55it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.21it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "C:\\Users\\cheny\\AppData\\Local\\Temp\\ipykernel_10356\\1329577407.py:144: RuntimeWarning: invalid value encountered in divide\n",
      "  distances = distances / np.linalg.norm(distances)\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.31it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.92it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.84it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.65it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.55it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.64it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.33it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.19it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.42it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.80it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.50it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.95it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.96it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.40it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.18it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.21it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.58it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.25it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.20it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.14it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.89it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.10it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.67it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.76it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.22it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.49it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.23it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.47it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.63it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.78it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.35it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.63it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.77it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.32it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.15it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.71it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.21it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.12it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.70it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.72it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 0it [00:00, ?it/s]\n",
      "LBFGS: 100%|██████████| 500/500 [00:17<00:00, 29.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1667.9582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adam: 100%|██████████| 500/500 [00:12<00:00, 39.13it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "C:\\Users\\cheny\\AppData\\Local\\Temp\\ipykernel_10356\\1329577407.py:144: RuntimeWarning: invalid value encountered in divide\n",
      "  distances = distances / np.linalg.norm(distances)\n",
      "Adam: 100%|██████████| 500/500 [00:13<00:00, 37.67it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:13<00:00, 37.35it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:13<00:00, 36.64it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 34.22it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.77it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.86it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.04it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.96it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 33.65it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 33.04it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.97it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.18it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.33it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.88it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.39it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.03it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.03it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.87it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.15it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.57it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.39it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.90it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.10it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.54it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.00it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.54it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.41it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.58it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.02it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.59it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.86it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.15it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.32it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.33it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.71it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.16it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.95it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.05it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.33it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.24it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.74it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.12it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.55it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.17it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.27it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.32it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.87it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.68it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.40it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.33it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.04it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.74it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.31it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.71it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.08it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.16it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.27it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.29it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.47it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.67it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.08it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.51it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.62it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.30it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.58it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.84it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.23it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.40it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.37it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.52it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.17it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.64it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.43it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.55it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.70it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:19<00:00, 25.89it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.21it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 27.95it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.06it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.20it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.18it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.12it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.47it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.63it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.90it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.96it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.20it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.61it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.15it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.69it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.83it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.46it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.06it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.18it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.05it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.52it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.35it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 27.92it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.75it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 0it [00:00, ?it/s]\n",
      "LBFGS: 100%|██████████| 500/500 [00:21<00:00, 23.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1687.3053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 34.46it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 34.79it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 34.55it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "C:\\Users\\cheny\\AppData\\Local\\Temp\\ipykernel_10356\\1329577407.py:144: RuntimeWarning: invalid value encountered in divide\n",
      "  distances = distances / np.linalg.norm(distances)\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 33.29it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 34.45it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 34.12it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 35.68it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 33.85it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 33.11it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 33.35it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.91it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.01it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.48it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.32it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.29it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.97it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.57it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.34it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.44it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.17it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.35it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.19it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.59it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.72it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.55it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.96it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.83it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.49it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.32it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.00it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.86it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.28it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.83it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.45it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.45it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.05it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.05it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.89it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.12it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.03it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.16it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.59it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.44it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.02it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.90it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.48it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.75it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.84it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.20it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.38it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.15it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.52it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.48it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.27it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.59it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.54it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.11it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.30it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.40it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.62it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.71it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.33it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.30it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.06it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.44it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.22it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.97it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.74it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.01it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.64it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 27.85it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.89it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.34it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.12it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.63it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.75it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.96it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.46it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.91it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.67it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.79it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.53it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.12it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.16it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.40it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.35it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.46it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.30it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.55it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.54it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.43it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.67it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.74it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.44it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.78it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.45it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.23it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.37it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.93it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.52it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 0it [00:00, ?it/s]\n",
      "LBFGS: 100%|██████████| 500/500 [00:32<00:00, 15.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1705.6893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 34.60it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 34.04it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 34.36it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 34.20it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 33.95it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.76it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.88it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 33.38it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.99it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "C:\\Users\\cheny\\AppData\\Local\\Temp\\ipykernel_10356\\1329577407.py:144: RuntimeWarning: invalid value encountered in divide\n",
      "  distances = distances / np.linalg.norm(distances)\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 33.66it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.24it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.68it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.96it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.99it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.63it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.02it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.64it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.28it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.48it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.86it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.29it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.58it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.21it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.44it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.44it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.93it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.90it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.22it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.15it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.07it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.85it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.87it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.97it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.09it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.41it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.20it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.62it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.39it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.22it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.66it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.24it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.49it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.46it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.54it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.41it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.71it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.24it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.57it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.39it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.92it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.58it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.33it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.15it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.50it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.56it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.74it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.19it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.45it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.45it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.60it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:22<00:00, 21.77it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.70it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.07it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.92it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.92it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.76it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.83it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.60it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.54it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.30it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.77it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.42it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.23it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.50it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.77it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.43it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.18it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.07it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 27.93it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.14it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.43it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.01it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.23it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.01it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 27.83it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.75it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.14it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.03it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.62it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.89it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.32it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 27.98it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.25it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.59it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 27.97it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.32it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 27.98it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.84it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.10it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.26it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 0it [00:00, ?it/s]\n",
      "LBFGS: 100%|██████████| 500/500 [00:43<00:00, 11.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1738.0686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.29it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "C:\\Users\\cheny\\AppData\\Local\\Temp\\ipykernel_10356\\1329577407.py:144: RuntimeWarning: invalid value encountered in divide\n",
      "  distances = distances / np.linalg.norm(distances)\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 33.69it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 33.69it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 34.11it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 34.31it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.17it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.37it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 33.80it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.63it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.33it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 33.63it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.62it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.65it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.87it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.14it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.64it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.14it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.40it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.73it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.06it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.83it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.49it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.98it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.99it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.61it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.11it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.50it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.86it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.69it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.44it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.30it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.66it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.84it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.14it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.06it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.61it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.18it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.19it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.50it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.94it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.73it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.10it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.47it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.28it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.50it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.13it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.89it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.36it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.28it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.64it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.83it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.84it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.11it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.37it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.87it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.57it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.35it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.40it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.20it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.24it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.72it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.13it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.59it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.54it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.14it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.67it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.26it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.22it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.02it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.81it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.97it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.13it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.10it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.87it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.83it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.06it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.34it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.61it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.97it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.54it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.51it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.88it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.51it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 27.98it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.96it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.34it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.64it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.11it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.31it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.43it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.53it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.20it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.60it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.01it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.76it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.22it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:23<00:00, 20.84it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.08it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.00it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.35it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 0it [00:00, ?it/s]\n",
      "LBFGS: 100%|██████████| 500/500 [00:52<00:00,  9.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1759.6995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 34.39it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 33.73it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 35.39it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 34.03it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 34.64it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 34.67it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 33.71it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.68it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.85it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.58it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.42it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 33.95it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 33.79it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.44it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.18it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.72it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.88it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.40it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.10it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.34it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.36it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "C:\\Users\\cheny\\AppData\\Local\\Temp\\ipykernel_10356\\1329577407.py:144: RuntimeWarning: invalid value encountered in divide\n",
      "  distances = distances / np.linalg.norm(distances)\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.32it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.28it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.39it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.18it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.58it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.48it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.78it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.83it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.41it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.98it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.84it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.25it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.29it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.69it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.49it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.83it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.85it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.48it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.49it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.55it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.76it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.72it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.18it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.24it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.17it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.99it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.66it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.22it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.71it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.61it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.29it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.90it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.93it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.34it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.17it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.29it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.29it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.71it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.25it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.78it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.47it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.08it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.24it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.57it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 27.84it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.17it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.87it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.91it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.97it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.53it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.61it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.21it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.21it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.04it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.21it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.44it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.70it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.74it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.03it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.45it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 27.82it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.00it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.31it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.41it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.40it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.76it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.14it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:19<00:00, 25.84it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.67it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.12it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.22it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.59it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.40it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.46it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.58it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.53it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.56it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.97it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.56it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 0it [00:00, ?it/s]\n",
      "LBFGS: 100%|██████████| 500/500 [00:21<00:00, 23.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1730.6620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 34.55it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 34.94it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 34.58it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 34.33it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 33.20it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.33it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.95it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 33.35it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.90it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.86it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.23it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 33.13it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 33.13it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.61it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.31it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.49it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.39it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.36it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.25it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.92it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.23it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.27it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.23it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.14it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.46it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.65it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.17it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.10it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.11it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.26it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.48it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.07it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.07it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.69it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.95it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.82it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.27it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.80it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.19it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.82it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.83it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.36it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.75it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.97it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.34it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.76it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.13it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.56it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.27it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.82it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.92it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.04it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.87it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.95it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.70it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.77it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "C:\\Users\\cheny\\AppData\\Local\\Temp\\ipykernel_10356\\1329577407.py:144: RuntimeWarning: invalid value encountered in divide\n",
      "  distances = distances / np.linalg.norm(distances)\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.84it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.33it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.21it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.02it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.65it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.67it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.79it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.14it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.76it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.04it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.16it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.60it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.14it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.25it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.53it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.50it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.61it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.45it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.40it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.37it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.69it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:19<00:00, 26.07it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.69it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.66it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.93it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.52it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.12it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.11it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 27.88it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.59it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.28it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:19<00:00, 26.17it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:19<00:00, 25.83it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.15it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.73it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:19<00:00, 25.44it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.99it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.59it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:20<00:00, 24.85it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:19<00:00, 25.81it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.12it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.35it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.17it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.07it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 0it [00:00, ?it/s]\n",
      "LBFGS: 100%|██████████| 500/500 [00:19<00:00, 25.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1725.4798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 34.68it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "C:\\Users\\cheny\\AppData\\Local\\Temp\\ipykernel_10356\\1329577407.py:144: RuntimeWarning: invalid value encountered in divide\n",
      "  distances = distances / np.linalg.norm(distances)\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 34.20it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 34.17it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 33.40it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.36it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 33.39it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.70it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 33.07it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.80it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.78it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.39it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.34it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.48it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.66it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.34it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.96it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.13it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.72it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.05it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.15it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.21it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.55it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.81it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.60it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.02it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.13it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.94it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.99it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.92it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.17it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.66it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.32it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.59it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.22it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.86it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.97it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.48it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.82it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.37it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.88it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.18it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.91it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.16it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.37it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.41it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.16it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.26it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.96it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.82it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.58it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.12it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.57it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.24it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.51it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.42it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.93it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.00it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.02it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.27it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.22it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.78it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.16it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.08it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 27.99it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.52it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.58it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.53it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.73it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.02it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.52it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.39it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 27.94it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.74it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.38it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.46it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.62it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.37it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.28it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.20it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.28it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.99it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.62it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.35it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.71it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.58it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.10it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:19<00:00, 25.57it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.43it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.23it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 27.89it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.29it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.35it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.12it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 27.81it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.04it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.92it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:21<00:00, 23.42it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.49it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.55it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.36it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 0it [00:00, ?it/s]\n",
      "LBFGS: 100%|██████████| 500/500 [00:20<00:00, 24.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1745.6025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adam: 100%|██████████| 500/500 [00:13<00:00, 35.71it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 34.26it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 34.17it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "C:\\Users\\cheny\\AppData\\Local\\Temp\\ipykernel_10356\\1329577407.py:144: RuntimeWarning: invalid value encountered in divide\n",
      "  distances = distances / np.linalg.norm(distances)\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.72it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.74it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.98it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.27it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.11it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.97it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.82it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.88it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.50it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.93it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.32it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.63it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.34it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.55it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.74it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.37it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.89it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.66it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.09it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.09it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.82it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.84it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.96it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.63it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.23it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.93it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.29it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.13it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.19it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.79it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.20it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.89it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.04it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.07it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.40it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.17it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.86it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.83it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.04it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.41it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.56it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 31.24it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.80it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.33it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.53it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.75it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.58it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.04it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.04it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.35it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.43it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.20it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.12it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.74it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.32it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.23it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.48it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.32it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.77it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.11it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.56it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 27.80it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 27.91it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 27.85it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.01it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.11it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.55it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.96it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.46it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.78it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.56it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:19<00:00, 26.13it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.47it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.48it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 27.89it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 27.84it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.17it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:19<00:00, 25.69it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.70it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.58it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:19<00:00, 25.19it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.40it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.94it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.62it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.30it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.10it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.09it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.54it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.18it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.98it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.52it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.10it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:19<00:00, 25.99it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:19<00:00, 25.77it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.01it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.94it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:19<00:00, 25.24it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 0it [00:00, ?it/s]\n",
      "LBFGS: 100%|██████████| 500/500 [00:51<00:00,  9.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1791.7206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 34.96it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "C:\\Users\\cheny\\AppData\\Local\\Temp\\ipykernel_10356\\1329577407.py:144: RuntimeWarning: invalid value encountered in divide\n",
      "  distances = distances / np.linalg.norm(distances)\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.69it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.58it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.54it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:14<00:00, 33.60it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.82it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 33.00it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 33.32it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.95it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.14it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.93it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 32.18it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 33.08it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.26it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.58it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.48it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.99it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:15<00:00, 31.97it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.39it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.99it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.74it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.80it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.49it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.92it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.15it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.58it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.86it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.50it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.21it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.69it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.35it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.42it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.29it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.25it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.37it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.97it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.77it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.25it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.49it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.23it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.20it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.94it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.83it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.78it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.83it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.94it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.46it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.29it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.13it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.31it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.49it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.16it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.01it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 30.47it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.67it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.42it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.16it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 29.16it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:16<00:00, 29.53it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.44it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.75it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 27.91it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.91it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.21it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.18it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.47it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.18it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.53it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.37it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.70it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.47it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.68it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.23it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 27.99it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.24it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.28it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.35it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 27.80it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.70it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:17<00:00, 28.19it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:19<00:00, 26.25it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.44it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.11it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.43it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.48it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.88it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.63it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:19<00:00, 26.07it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:20<00:00, 24.86it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:19<00:00, 26.15it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 27.07it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.36it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:19<00:00, 26.16it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.40it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:19<00:00, 26.20it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.50it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:19<00:00, 26.02it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:20<00:00, 24.83it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:19<00:00, 25.95it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 100%|██████████| 500/500 [00:18<00:00, 26.61it/s]\n",
      "LBFGS: 0it [00:00, ?it/s]\n",
      "Adam: 0it [00:00, ?it/s]\n",
      "LBFGS: 100%|██████████| 500/500 [00:24<00:00, 20.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1773.7092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#RAR-G方法，对1000个点，先选择10个点训练500次，然后每500次迭代重采样100个点，选出其中残差最大的10个点添加到训练点中；最后总共有1000个点，共训练10000次\n",
    "seeds = [0, 123, 321, 1234, 4321, 54321, 654321, 7654321, 87654321, 987654321] #设置10个种子\n",
    "\n",
    "nu = 0.01/np.pi\n",
    "#设置噪声水平为0\n",
    "noise = 0.0        \n",
    "\n",
    "N_u = 100\n",
    "N_f = 1000\n",
    "N_f_ceshi = 400\n",
    "#定义一个列表layers，其中包含了神经网络的层数和每一层的神经元数量\n",
    "layers = [2, 20, 20, 20, 20, 20, 20, 20, 20, 2, 1]\n",
    "#读取名为burgers_shock的Matlab文件，文件中的数据存储在data变量中。这里的路径也要随着设备的情况修改 \n",
    "data = scipy.io.loadmat('../../data/burgers_shock.mat')\n",
    "#从data字典中取出变量tt和x的值，并转换为一维数组（flatten方法），最后tongg[:,None]将一维数组转换为二维数组\n",
    "t = data['t'].flatten()[:,None]\n",
    "x = data['x'].flatten()[:,None]\n",
    "Exact = np.real(data['usol']).T #从data数据中取出usol的值，并取实部，最后转置，赋值给Exact\n",
    "#生成一个二位网络，X和T是输出的二维数组\n",
    "#这个点结果是X和T均为形状为[len(t),len(x)]的二维数组，X的每一行都是x，一共len(t)行，T的每一列都是t，一共len(x)列\n",
    "X, T = np.meshgrid(x,t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))  #按列堆叠数组，X_star是一个二维数组，其中第一列是X的展平，第二列是T的展平\n",
    "u_star = Exact.flatten()[:,None]    #对Exact_u使用flatten方法将其转换为一维数组，最后使用[:,None]将其转换为二维数组         \n",
    "\n",
    "# Doman bounds，分别获得X_star的相应列上的最小值和最大值，赋值给lb和ub,也就是说lb是x和t的最小值，ub是x和t的最大值，即lb和ub分别为[-1,0]和[1,1]\n",
    "lb = X_star.min(0)\n",
    "ub = X_star.max(0)    \n",
    "\n",
    "\n",
    "#生成初值和边界值的训练基础数据\n",
    "xx1 = np.hstack((X[0:1,:].T, T[0:1,:].T)) #分别取X，T的第一行的转置(分别是x和全0列)，分别构成xx1的第一列和第二列\n",
    "uu1 = Exact[0:1,:].T #取Exact的第一行的转置，赋值给uu1\n",
    "xx2 = np.hstack((X[:,0:1], T[:,0:1])) #分别取X，T的第一列(分别是全-1列和t)，分别构成xx2的第一列和第二列\n",
    "uu2 = Exact[:,0:1] #取Exact的第一列，赋值给uu2\n",
    "xx3 = np.hstack((X[:,-1:], T[:,-1:])) #分别取X，T的最后一列(分别是全1列和t)，分别构成xx3的第一列和第二列\n",
    "uu3 = Exact[:,-1:] #取Exact的最后一列，赋值给uu3\n",
    "\n",
    "X_u_train_all = np.vstack([xx1, xx2, xx3]) #X_u_train=(xx1;xx2;xx3)\n",
    "\n",
    "u_train_all = np.vstack([uu1, uu2, uu3]) #u_train=(uu1;uu2;uu3)\n",
    "\n",
    "# #生成配位点训练基础数据\n",
    "# X_f_train = quasirandom(N_f, \"LHS\")  #lhs函数采用拉丁超采样方法，生成一个近似均匀分布的多维样本点集，表示生产的样本有两个特征，共N_f个样本数量，所以返回的是一个形状为（N_f，2）的数组，每一行都是一个2维的样本点，所有样本点都在[0,1]范围内，并对该样本集进行缩放，把每个样本从[0,1]区间缩放到[lb,ub]区域内，即得到了指定范围内均匀分布的样本X_f_train。\n",
    "\n",
    "# X_f_train = np.vstack((X_f_train, X_u_train)) #按行堆叠数组，即将X_f_train和X_u_train按行合并，得到一个新的数组X_f_train\n",
    "\n",
    "\n",
    "error_u = [] #创建一个空列表，用于存储误差值\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed) #设置随机数种子\n",
    "\n",
    "    \n",
    "\n",
    "    #1.生成初值边界值训练数据，以及测试数据\n",
    "\n",
    "    #从所有的初值边界值训练基础数据中选取N_u=100个点\n",
    "    idx = np.random.choice(X_u_train_all.shape[0], N_u, replace=False) #从0~数组X_u_train的行数 中随机选择N_u个数，replace=False表示不允许重复选择，最后将这N_u个数赋值给idx\n",
    "    X_u_train = X_u_train_all[idx, :] #从X_u_train中选取idx对应的的N_u行，赋值给X_u_train\n",
    "    u_train = u_train_all[idx,:] #从u_train中选取idx对应的的N_u行，赋值给u_train\n",
    "\n",
    "    \n",
    "\n",
    "    #2.生成配位点并进行训练\n",
    "\n",
    "\n",
    "\n",
    "    num_iter = 50 #迭代次数\n",
    "\n",
    "    #先训练500次\n",
    "    #采样配位点10个\n",
    "    N_f_1 = 10\n",
    "    X_f_train = caiyang(N_f_1, \"LHS\")\n",
    "\n",
    "    #创建PINN模型并输入各种参数     \n",
    "    model = PhysicsInformedNN(X_u_train, u_train, X_f_train, layers, lb, ub, nu, X_star, u_star)\n",
    "\n",
    "    #获取当前时间并赋值给start_time  \n",
    "    start_time = time.time()   \n",
    "    #开始训练模型            \n",
    "    model.train(500,0)\n",
    "\n",
    "\n",
    "    #训练结束后，每500次迭代重采样一次100个点，并选出其中残差最大的10个点添加到训练点中；最后总共有1000个点，共训练50000次\n",
    "    for iter in range(501, 50001, 500): #每500次迭代\n",
    "        N_f_new = 100 #重新采样100个点\n",
    "        # 生成新的X_f_train数据\n",
    "        X_f_train_new = lb + (ub-lb)*lhs(2, N_f_new)\n",
    "\n",
    "        #计算混沌情况\n",
    "        #对于所有的采样点\n",
    "        x0 = X_f_train_new[:, 0:1] #取X_f_train_new的第一列，赋值给x0，(N_f_new,1)形状\n",
    "        t0 = X_f_train_new[:, 1:2] #取X_f_train_new的第二列，赋值给t0\n",
    "        # 利用x0和t0计算x{t}和t{t}，存储在xs中\n",
    "        xs = [] #初始化xs\n",
    "        x,t = model.hidden_predict(x0,t0) #调用predict方法，传入X_f_train_new，得到x和t，这里x和t形状均为(N_f_new,)，因此下一步需要reshape\n",
    "        x = x.reshape(-1,1) #将x的形状变为(N_f_new,1)（这一步是为了之后能重复输入神经网络）\n",
    "        t = t.reshape(-1,1) #将t的形状变为(N_f_new,1)（这一步是为了之后能重复输入神经网络）\n",
    "\n",
    "        for i in range(num_iter): #循环num_iter次\n",
    "            x,t = model.hidden_predict(x,t) #每次计算隐藏层输出，得到的x和t形状均为(N_f_new,)，因此下一步需要reshape\n",
    "            x = x.reshape(-1,1) #将x的形状变为(N_f_new,1)（这一步是为了之后能重复输入神经网络）\n",
    "            t = t.reshape(-1,1) #将t的形状变为(N_f_new,1)（这一步是为了之后能重复输入神经网络）\n",
    "            xs.append([x,t]) #将x的数据添加到xs中\n",
    "        #最后得到的xs是一个列表，列表中的每个元素都是一个列表（num_iter个元素），每个列表中有两个元素，分别代表x和t，长度均为N_f_new，对应原始采样点的迭代结果\n",
    "\n",
    "\n",
    "        # 给所有采样点加上一个很小的扰动\n",
    "        x1 = x0 + np.random.normal(0, 0.0001) #加上一个很小的扰动，(N_f_new,1)形状\n",
    "        t1 = t0 + np.random.normal(0, 0.0001)\n",
    "        # 利用x0{1}和t0{1}计算x{t1}和t{t1}，存储在xs1中\n",
    "        xs1 = [] #初始化xs1\n",
    "        x,t = model.hidden_predict(x1,t1) #调用predict方法，传入X_f_train_new，得到x和t，这里x和t形状均为(N_f_new,)，因此下一步需要reshape\n",
    "        x = x.reshape(-1,1) #将x的形状变为(N_f_new,1)（这一步是为了之后能重复输入神经网络）\n",
    "        t = t.reshape(-1,1) #将t的形状变为(N_f_new,1)（这一步是为了之后能重复输入神经网络）\n",
    "\n",
    "        for i in range(num_iter): #循环num_iter次\n",
    "            x,t = model.hidden_predict(x,t) #每次计算隐藏层输出，得到的x和t形状均为(N_f_new,)，因此下一步需要reshape\n",
    "            x = x.reshape(-1,1) #将x的形状变为(N_f_new,1)\n",
    "            t = t.reshape(-1,1) #将t的形状变为(N_f_new,1)\n",
    "            xs1.append([x,t]) #将x的数据添加到xs1中\n",
    "        #最后得到的xs1是一个列表，列表中的每个元素都是一个列表（num_iter个元素），每个列表中有两个元素，分别代表x和t，长度均为N_f_new，对应加了扰动后的采样点的迭代结果\n",
    "\n",
    "        # 计算最后一次迭代的隐藏层输出，即最后一次迭代的x和t\n",
    "        last_iter_xs = np.array(xs[-1]) #转换为数组，便于之后计算距离\n",
    "        last_iter_xs1 = np.array(xs1[-1])\n",
    "        #这两个数组的形状均为(2,N_f_new,1)，第一个代表x和t，第二个代表N_f_new个样本点得到的结果，第三个代表1个数\n",
    "\n",
    "        # 计算这两个点的欧氏距离\n",
    "        distances = np.linalg.norm(last_iter_xs - last_iter_xs1, axis=0)\n",
    "        #得到的是一个形状为（N_f_new,1）的数组，每个元素代表了两个点之间的欧氏距离，这里点在xt平面上\n",
    "\n",
    "        distances = distances.flatten()\n",
    "\n",
    "        _, residual = model.predict(X_f_train_new)\n",
    "\n",
    "        # 计算残差的绝对值\n",
    "        abs_residual = np.abs(residual)\n",
    "        #将二维数组转换为一维数组\n",
    "        abs_residual = abs_residual.flatten()\n",
    "\n",
    "        #对distances进行归一化\n",
    "        distances = distances / np.linalg.norm(distances)\n",
    "\n",
    "        #对abs_residual进行归一化\n",
    "        abs_residual = abs_residual / np.linalg.norm(abs_residual)\n",
    "\n",
    "        # 计算信息量\n",
    "        xinxi = distances + abs_residual\n",
    "\n",
    "        \n",
    "\n",
    "        # 找出绝对值最大的10个值的索引\n",
    "        topk_indices = np.argpartition(xinxi, -N_f_1)[-N_f_1:] #该函数会对数组进行排序，使得指定的k个最大值出现在数组的最后k给位置上，并获取最后1000个元素\n",
    "\n",
    "        # 使用这些索引来提取对应的数据\n",
    "        X_f_train_topk = X_f_train_new[topk_indices]\n",
    "\n",
    "        X_f_train = np.vstack((X_f_train, X_f_train_topk)) #与之前的训练数据合并\n",
    "\n",
    "        # 更新模型中的X_f_train数据\n",
    "        model.X_f = X_f_train\n",
    "\n",
    "        # 在更新数据后的模型上进行训练500次\n",
    "        model.train(500,0)\n",
    "\n",
    "\n",
    "\n",
    "    model.train(0,500) #使用LBFGS训练500次\n",
    "    #所有训练结束后获取当前时间并减去start_time，得到训练时间并赋值给elapsed\n",
    "    elapsed = time.time() - start_time\n",
    "    #打印训练所花时间                \n",
    "    print('Training time: %.4f' % (elapsed))\n",
    "\n",
    "    # 训练结束后，再次使用模型进行预测，并计算误差\n",
    "    u_pred, f_pred = model.predict(X_star)\n",
    "    error_u.append(np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)) #计算误差，然后将误差添加到error_u列表中\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5202765768338299, 0.5498189856925179, 0.8054262198745831, 0.2836623431751703, 0.7163985307835498, 0.8486951661259542, 0.45799139947295237, 1.0888879509613618, 0.18105234189218838, 0.5686642080465825]\n",
      "Error u of chaos active learning(LHS sampling): 6.020874e-01\n"
     ]
    }
   ],
   "source": [
    "print(error_u)\n",
    "\n",
    "error_of_u = sum(error_u)/len(error_u)\n",
    "\n",
    "print('Error u of fuhe active learning(LHS sampling): %e' % (error_of_u)) #打印误差\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.8705629e-04 8.9099992e-04 9.2152786e-01 4.1344049e-04 0.0000000e+00\n",
      " 1.0493009e-04 9.2165351e-02 1.2333426e-03 6.9974393e-02 1.7311827e-03\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 6.6773697e-05 3.3725810e-05\n",
      " 3.2573353e-04 6.1085656e-02 2.3866820e-04 5.8678607e-04 1.2754779e-03\n",
      " 1.3490324e-05 1.0311278e-03 3.9330713e-05 0.0000000e+00 3.8371190e-02\n",
      " 5.0588715e-06 0.0000000e+00 0.0000000e+00 3.5009183e-02 1.3693595e-02\n",
      " 1.0117743e-05 0.0000000e+00 1.8392940e-04 1.9672517e-02 1.9634945e-02\n",
      " 3.3725810e-05 9.1744128e-05 1.1096766e-03 5.6586344e-02 6.9336075e-04\n",
      " 0.0000000e+00 6.7451620e-05 8.9932937e-04 1.7345692e-03 2.4366751e-04\n",
      " 0.0000000e+00 3.8156399e-05 3.4089771e-04 1.0027405e-04 5.0269562e-04\n",
      " 1.6064959e-03 1.8392940e-04 1.3216741e-01 5.9728971e-04 6.6031106e-03\n",
      " 2.7437746e-03 9.6009183e-04 6.3461903e-04 1.1062889e-04 1.7157788e-03\n",
      " 1.0704864e-03 3.2950360e-01 2.1468273e-04 7.0033048e-04 1.4227986e-03\n",
      " 2.4320028e-05 2.8666938e-05 4.8438823e-04 2.6980648e-05 5.4504763e-04\n",
      " 1.3063343e-03 1.2009419e-04 4.8206961e-03 2.3608067e-05 2.3554526e-03\n",
      " 8.2335195e-05 0.0000000e+00 9.9211221e-04 4.3975227e-03 4.3991390e-03\n",
      " 8.2935026e-04 4.2473103e-04 7.4310657e-03 2.4486291e-03 3.1261935e-04\n",
      " 5.2681400e-05 2.9680007e-03 5.1590567e-04 1.6842692e-03 1.8771678e-03\n",
      " 2.0308427e-03 1.2328387e-04 0.0000000e+00 0.0000000e+00 1.4793297e-04\n",
      " 9.5390997e-06 8.3577435e-04 3.7122911e-04 6.5650215e-04 2.3056207e-02]\n",
      "[1.88264400e-01 7.78524484e-03 7.50318393e-02 5.11918664e-02\n",
      " 7.24313781e-04 1.58345734e-03 2.05228981e-02 4.13957946e-02\n",
      " 3.41413845e-03 3.79540324e-02 3.36754657e-02 3.20584350e-03\n",
      " 4.41822857e-02 4.39154916e-03 8.43090646e-04 1.10528395e-02\n",
      " 1.58599410e-02 2.13725381e-02 4.34235251e-03 1.48808921e-03\n",
      " 1.09083822e-03 1.38115676e-04 1.59354822e-03 7.49121793e-03\n",
      " 4.19568084e-02 2.78347135e-02 2.96418235e-04 3.69573158e-04\n",
      " 2.55393498e-02 3.80133279e-03 5.85301733e-03 3.53960437e-03\n",
      " 5.74274221e-04 4.15873043e-02 1.20220985e-02 3.52683943e-03\n",
      " 1.92349160e-03 7.75972083e-02 6.43512964e-01 1.06695136e-02\n",
      " 7.29584019e-04 2.84896158e-02 1.01084600e-03 5.35677113e-02\n",
      " 4.70643718e-04 1.70395011e-03 1.06044731e-03 9.76323243e-03\n",
      " 3.47879180e-03 8.04601833e-02 2.08546198e-03 8.15748274e-02\n",
      " 4.46523316e-02 1.21436873e-02 7.39048002e-03 5.05617866e-03\n",
      " 8.32778290e-02 3.18220654e-03 5.13769686e-03 8.73805806e-02\n",
      " 1.79143175e-02 6.73608063e-03 8.45525861e-02 7.73817524e-02\n",
      " 3.09921116e-01 5.71589568e-04 1.62824243e-02 6.36924151e-03\n",
      " 6.63840473e-02 3.29809845e-03 5.74845530e-04 5.15322434e-03\n",
      " 6.59820915e-04 2.96947435e-02 3.12916815e-01 1.46415574e-03\n",
      " 1.13080181e-02 3.07795987e-03 2.31524347e-03 1.29204080e-01\n",
      " 1.08081009e-03 5.57357371e-02 5.05241334e-01 3.00377235e-02\n",
      " 3.78451520e-03 1.52268657e-03 3.79360304e-03 8.46406538e-03\n",
      " 1.34697312e-03 6.67898916e-03 4.05336730e-03 5.21109160e-03\n",
      " 2.60561967e-04 1.90553779e-04 2.50101741e-03 1.16909726e-03\n",
      " 7.68029224e-03 4.93328611e-04 1.20293269e-04 2.73687742e-03]\n",
      "[1.8925145e-01 8.6762449e-03 9.9655968e-01 5.1605307e-02 7.2431378e-04\n",
      " 1.6883875e-03 1.1268825e-01 4.2629138e-02 7.3388532e-02 3.9685216e-02\n",
      " 3.3675466e-02 3.2058435e-03 4.4182286e-02 4.4583227e-03 8.7681646e-04\n",
      " 1.1378573e-02 7.6945595e-02 2.1611206e-02 4.9291383e-03 2.7635670e-03\n",
      " 1.1043285e-03 1.1692435e-03 1.6328789e-03 7.4912179e-03 8.0328003e-02\n",
      " 2.7839772e-02 2.9641823e-04 3.6957316e-04 6.0548533e-02 1.7494928e-02\n",
      " 5.8631352e-03 3.5396044e-03 7.5820362e-04 6.1259821e-02 3.1657044e-02\n",
      " 3.5605652e-03 2.0152358e-03 7.8706883e-02 7.0009929e-01 1.1362874e-02\n",
      " 7.2958402e-04 2.8557068e-02 1.9101754e-03 5.5302281e-02 7.1431126e-04\n",
      " 1.7039501e-03 1.0986037e-03 1.0104130e-02 3.5790659e-03 8.0962881e-02\n",
      " 3.6919578e-03 8.1758760e-02 1.7681974e-01 1.2740977e-02 1.3993591e-02\n",
      " 7.7999532e-03 8.4237918e-02 3.8168256e-03 5.2483259e-03 8.9096360e-02\n",
      " 1.8984804e-02 3.3623967e-01 8.4767267e-02 7.8082085e-02 3.1134391e-01\n",
      " 5.9590960e-04 1.6311090e-02 6.8536298e-03 6.6411026e-02 3.8431461e-03\n",
      " 1.8811799e-03 5.2733184e-03 5.4805172e-03 2.9718351e-02 3.1527227e-01\n",
      " 1.5464909e-03 1.1308018e-02 4.0700720e-03 6.7127664e-03 1.3360322e-01\n",
      " 1.9101603e-03 5.6160469e-02 5.1267242e-01 3.2486353e-02 4.0971343e-03\n",
      " 1.5753680e-03 6.7616040e-03 8.9799706e-03 3.0312422e-03 8.5561574e-03\n",
      " 6.0842102e-03 5.3343754e-03 2.6056197e-04 1.9055378e-04 2.6489503e-03\n",
      " 1.1786363e-03 8.5160667e-03 8.6455769e-04 7.7679544e-04 2.5793085e-02]\n",
      "[ 6 52 79  0 61 64 38 74  2 82]\n"
     ]
    }
   ],
   "source": [
    "print(distances)\n",
    "print(abs_residual)\n",
    "print(xinxi)\n",
    "print(topk_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
