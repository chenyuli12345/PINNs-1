{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "Other supported backends: tensorflow.compat.v1, tensorflow, jax, paddle.\n",
      "paddle supports more examples now and is recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "'compile' took 0.559996 s\n",
      "\n",
      "Training model...\n",
      "\n",
      "Step      Train loss                        Test loss                         Test metric\n",
      "0         [5.33e-01, 1.66e-01, 4.62e-01]    [5.33e-01, 1.66e-01, 4.62e-01]    []  \n",
      "1000      [4.34e-02, 2.26e-03, 6.42e-02]    [4.34e-02, 2.26e-03, 6.42e-02]    []  \n",
      "2000      [3.20e-02, 2.64e-04, 4.78e-02]    [3.20e-02, 2.64e-04, 4.78e-02]    []  \n",
      "3000      [2.19e-02, 1.76e-04, 3.24e-02]    [2.19e-02, 1.76e-04, 3.24e-02]    []  \n",
      "4000      [1.57e-02, 6.62e-05, 1.53e-02]    [1.57e-02, 6.62e-05, 1.53e-02]    []  \n",
      "5000      [8.77e-03, 3.61e-05, 6.88e-03]    [8.77e-03, 3.61e-05, 6.88e-03]    []  \n",
      "6000      [6.58e-03, 1.91e-05, 5.76e-03]    [6.58e-03, 1.91e-05, 5.76e-03]    []  \n",
      "7000      [6.91e-03, 1.11e-05, 5.45e-03]    [6.91e-03, 1.11e-05, 5.45e-03]    []  \n",
      "8000      [6.05e-03, 1.01e-05, 4.98e-03]    [6.05e-03, 1.01e-05, 4.98e-03]    []  \n",
      "9000      [4.58e-03, 5.34e-06, 4.45e-03]    [4.58e-03, 5.34e-06, 4.45e-03]    []  \n",
      "10000     [4.43e-03, 7.25e-06, 4.24e-03]    [4.43e-03, 7.25e-06, 4.24e-03]    []  \n",
      "11000     [3.77e-03, 5.44e-06, 3.93e-03]    [3.77e-03, 5.44e-06, 3.93e-03]    []  \n",
      "12000     [3.47e-03, 5.30e-06, 3.76e-03]    [3.47e-03, 5.30e-06, 3.76e-03]    []  \n",
      "13000     [3.21e-03, 4.66e-06, 3.60e-03]    [3.21e-03, 4.66e-06, 3.60e-03]    []  \n",
      "14000     [3.00e-03, 4.29e-06, 3.47e-03]    [3.00e-03, 4.29e-06, 3.47e-03]    []  \n",
      "15000     [2.96e-03, 6.78e-06, 3.37e-03]    [2.96e-03, 6.78e-06, 3.37e-03]    []  \n",
      "\n",
      "Best model at step 15000:\n",
      "  train loss: 6.34e-03\n",
      "  test loss: 6.34e-03\n",
      "  test metric: []\n",
      "\n",
      "'train' took 49.481879 s\n",
      "\n",
      "Compiling model...\n",
      "'compile' took 0.000564 s\n",
      "\n",
      "Training model...\n",
      "\n",
      "Step      Train loss                        Test loss                         Test metric\n",
      "15000     [2.96e-03, 6.78e-06, 3.37e-03]    [2.96e-03, 6.78e-06, 3.37e-03]    []  \n",
      "16000     [4.37e-04, 7.37e-07, 3.86e-04]    [4.37e-04, 7.37e-07, 3.86e-04]    []  \n",
      "17000     [2.28e-04, 9.68e-07, 1.23e-04]    [2.28e-04, 9.68e-07, 1.23e-04]    []  \n",
      "18000     [1.16e-04, 5.78e-07, 5.59e-05]    [1.16e-04, 5.78e-07, 5.59e-05]    []  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15000\u001b[39m)\n\u001b[0;32m     39\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL-BFGS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m losshistory, train_state \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m dde\u001b[38;5;241m.\u001b[39msaveplot(losshistory, train_state, issave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, isplot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     43\u001b[0m X, y_true \u001b[38;5;241m=\u001b[39m gen_testdata()\n",
      "File \u001b[1;32mc:\\Users\\lcy\\anaconda3\\envs\\pytorchgpu\\lib\\site-packages\\deepxde\\utils\\internal.py:22\u001b[0m, in \u001b[0;36mtiming.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     21\u001b[0m     ts \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mdefault_timer()\n\u001b[1;32m---> 22\u001b[0m     result \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     23\u001b[0m     te \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mdefault_timer()\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\lcy\\anaconda3\\envs\\pytorchgpu\\lib\\site-packages\\deepxde\\model.py:644\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, iterations, batch_size, display_every, disregard_previous_best, callbacks, model_restore_path, model_save_path, epochs)\u001b[0m\n\u001b[0;32m    642\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_tensorflow_tfp()\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backend_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 644\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_pytorch_lbfgs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backend_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaddle\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_paddle_lbfgs()\n",
      "File \u001b[1;32mc:\\Users\\lcy\\anaconda3\\envs\\pytorchgpu\\lib\\site-packages\\deepxde\\model.py:766\u001b[0m, in \u001b[0;36mModel._train_pytorch_lbfgs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mon_batch_begin()\n\u001b[0;32m    763\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_state\u001b[38;5;241m.\u001b[39mset_data_train(\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mtrain_next_batch(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[0;32m    765\u001b[0m )\n\u001b[1;32m--> 766\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    767\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_aux_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    772\u001b[0m n_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mstate_dict()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_iter\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prev_n_iter \u001b[38;5;241m==\u001b[39m n_iter:\n\u001b[0;32m    774\u001b[0m     \u001b[38;5;66;03m# Converged\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lcy\\anaconda3\\envs\\pytorchgpu\\lib\\site-packages\\deepxde\\model.py:562\u001b[0m, in \u001b[0;36mModel._train_step\u001b[1;34m(self, inputs, targets, auxiliary_vars)\u001b[0m\n\u001b[0;32m    560\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_step(inputs, targets, auxiliary_vars)\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backend_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 562\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauxiliary_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backend_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjax\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;66;03m# TODO: auxiliary_vars\u001b[39;00m\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_step(\n\u001b[0;32m    566\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt_state, inputs, targets\n\u001b[0;32m    567\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\lcy\\anaconda3\\envs\\pytorchgpu\\lib\\site-packages\\deepxde\\model.py:362\u001b[0m, in \u001b[0;36mModel._compile_pytorch.<locals>.train_step\u001b[1;34m(inputs, targets, auxiliary_vars)\u001b[0m\n\u001b[0;32m    359\u001b[0m     total_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m total_loss\n\u001b[1;32m--> 362\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\lcy\\anaconda3\\envs\\pytorchgpu\\lib\\site-packages\\torch\\optim\\optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    383\u001b[0m             )\n\u001b[1;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lcy\\anaconda3\\envs\\pytorchgpu\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lcy\\anaconda3\\envs\\pytorchgpu\\lib\\site-packages\\torch\\optim\\lbfgs.py:391\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    389\u001b[0m     d \u001b[38;5;241m=\u001b[39m r \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmul(q, H_diag)\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_old):\n\u001b[1;32m--> 391\u001b[0m         be_i \u001b[38;5;241m=\u001b[39m \u001b[43mold_dirs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m ro[i]\n\u001b[0;32m    392\u001b[0m         r\u001b[38;5;241m.\u001b[39madd_(old_stps[i], alpha\u001b[38;5;241m=\u001b[39mal[i] \u001b[38;5;241m-\u001b[39m be_i)\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prev_flat_grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\lcy\\anaconda3\\envs\\pytorchgpu\\lib\\site-packages\\torch\\utils\\_device.py:77\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[1;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"Backend supported: tensorflow.compat.v1, tensorflow, pytorch, paddle\"\"\"\n",
    "import deepxde as dde\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def gen_testdata():\n",
    "    data = np.load(\"../dataset/Burgers.npz\")\n",
    "    t, x, exact = data[\"t\"], data[\"x\"], data[\"usol\"].T\n",
    "    xx, tt = np.meshgrid(x, t)\n",
    "    X = np.vstack((np.ravel(xx), np.ravel(tt))).T\n",
    "    y = exact.flatten()[:, None]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def pde(x, y):\n",
    "    dy_x = dde.grad.jacobian(y, x, i=0, j=0)\n",
    "    dy_t = dde.grad.jacobian(y, x, i=0, j=1)\n",
    "    dy_xx = dde.grad.hessian(y, x, i=0, j=0)\n",
    "    return dy_t + y * dy_x - 0.01 / np.pi * dy_xx\n",
    "\n",
    "\n",
    "geom = dde.geometry.Interval(-1, 1)\n",
    "timedomain = dde.geometry.TimeDomain(0, 0.99)\n",
    "geomtime = dde.geometry.GeometryXTime(geom, timedomain)\n",
    "\n",
    "bc = dde.icbc.DirichletBC(geomtime, lambda x: 0, lambda _, on_boundary: on_boundary)\n",
    "ic = dde.icbc.IC(\n",
    "    geomtime, lambda x: -np.sin(np.pi * x[:, 0:1]), lambda _, on_initial: on_initial\n",
    ")\n",
    "\n",
    "data = dde.data.TimePDE(\n",
    "    geomtime, pde, [bc, ic], num_domain=2540, num_boundary=80, num_initial=160\n",
    ")\n",
    "net = dde.nn.FNN([2] + [20] * 3 + [1], \"tanh\", \"Glorot normal\")\n",
    "model = dde.Model(data, net)\n",
    "\n",
    "model.compile(\"adam\", lr=1e-3)\n",
    "model.train(iterations=15000)\n",
    "model.compile(\"L-BFGS\")\n",
    "losshistory, train_state = model.train()\n",
    "dde.saveplot(losshistory, train_state, issave=True, isplot=True)\n",
    "\n",
    "X, y_true = gen_testdata()\n",
    "y_pred = model.predict(X)\n",
    "f = model.predict(X, operator=pde)\n",
    "print(\"Mean residual:\", np.mean(np.absolute(f)))\n",
    "print(\"L2 relative error:\", dde.metrics.l2_relative_error(y_true, y_pred))\n",
    "np.savetxt(\"test.dat\", np.hstack((X, y_true, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
