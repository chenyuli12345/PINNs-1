{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribute\n",
    "\n",
    "**Original Work**: *Maziar Raissi, Paris Perdikaris, and George Em Karniadakis*\n",
    "\n",
    "**Github Repo** : https://github.com/maziarraissi/PINNs\n",
    "\n",
    "**Link:** https://github.com/maziarraissi/PINNs/tree/master/appendix/continuous_time_identification%20(Burgers)\n",
    "\n",
    "@article{raissi2017physicsI,\n",
    "  title={Physics Informed Deep Learning (Part I): Data-driven Solutions of Nonlinear Partial Differential Equations},\n",
    "  author={Raissi, Maziar and Perdikaris, Paris and Karniadakis, George Em},\n",
    "  journal={arXiv preprint arXiv:1711.10561},\n",
    "  year={2017}\n",
    "}\n",
    "\n",
    "@article{raissi2017physicsII,\n",
    "  title={Physics Informed Deep Learning (Part II): Data-driven Discovery of Nonlinear Partial Differential Equations},\n",
    "  author={Raissi, Maziar and Perdikaris, Paris and Karniadakis, George Em},\n",
    "  journal={arXiv preprint arXiv:1711.10566},\n",
    "  year={2017}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#collections是python一个内置模块，提供了一些有用的数据结构\n",
    "from collections import OrderedDict  #这个类是字典dict的一个子类，用于创建有序的字典。普通字典中元素顺序是无序的，在OrderedDict中元素的顺序是有序的，元素的顺序是按照它们被添加到字典中的顺序决定的。\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#下面的`scipy`是一个用于科学计算和技术计算的Python库，提供了许多高级的数学函数和便利的操作，包括数值积分、插值、优化、图像处理、统计等。\n",
    "import scipy.io #导入了scipy库中的io模块。scipy.io模块包含了一些用于文件输入/输出的函数，例如读取和写入.mat文件（MATLAB格式）。\n",
    "from scipy.interpolate import griddata #`scipy.interpolate`是`scipy`库中的一个模块，提供了许多插值工具，用于在给定的离散数据点之间进行插值和拟合。`griddata`是这个模块中的一个函数，用于在无规则的数据点上进行插值。\n",
    "from pyDOE import lhs #`pyDOE`是一个Python库，用于设计实验。它提供了一些函数来生成各种设计，如因子设计、拉丁超立方设计等。`lhs`是库中的一个函数，全名为\"Latin Hypercube Sampling\"，拉丁超立方采样。这是一种统计方法，用于生成一个近似均匀分布的多维样本点集。它在参数空间中生成一个非常均匀的样本，这对于高维数值优化问题非常有用，因为它可以更好地覆盖参数空间。\n",
    "from mpl_toolkits.mplot3d import Axes3D #`mpl_toolkits.mplot3d`是`matplotlib`库的一个模块，用于创建三维图形。`Axes3D`是`mpl_toolkits.mplot3d`模块中的一个类，用于创建一个三维的坐标轴。可以在这个坐标轴上绘制三维的图形，如曲线、曲面等。\n",
    "import time #一个内置模块，用于处理时间相关的操作。\n",
    "import matplotlib.gridspec as gridspec #是`matplotlib`库的一个模块，用于创建一个网格布局来放置子图。在`matplotlib`中可以创建一个或多个子图（subplot），每个子图都有自己的坐标轴，并可以在其中绘制图形。`gridspec`模块提供了一个灵活的方式来创建和放置子图。\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable #`mpl_toolkits.axes_grid1`是`matplotlib`库的一个模块，提供了一些高级的工具来控制matplotlib图形中的坐标轴和颜色条。`make_axes_locatable`是模块中的一个函数，用于创建一个可分割的坐标轴。可以在这个坐标轴的四个方向（上、下、左、右）添加新的坐标轴或颜色条。\n",
    "\n",
    "import math\n",
    "import pandas as pd #pandas用于处理结构化数据\n",
    "from scipy.io import savemat #导入sys模块。sys模块提供了一些变量和函数，用于与 Python解释器进行交互和访问。例如，sys.path 是一个 Python 在导入模块时会查找的路径列表，sys.argv 是一个包含命令行参数的列表，sys.exit() 函数可以用于退出 Python 程序。导入 sys 模块后，你就可以在你的程序中使用这些变量和函数了。\n",
    "\n",
    "import torch\n",
    "#collections是python一个内置模块，提供了一些有用的数据结构\n",
    "from collections import OrderedDict  #这个类是字典dict的一个子类，用于创建有序的字典。普通字典中元素顺序是无序的，在OrderedDict中元素的顺序是有序的，元素的顺序是按照它们被添加到字典中的顺序决定的。\n",
    "\n",
    "import skopt #用于优化问题的库，特别是机器学习中的超参数优化\n",
    "from distutils.version import LooseVersion #distutils是Python的一个标准库，用于构建和安装Python包。LooseVersion是一个类，用于比较版本号\n",
    "\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm #一个快速，可扩展的python进度条库，可以在python长循环中添加一个进度提示信息，用户只需要封装任意的迭代器tqdm(iterator)。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# torch.cuda.set_device(1) #设置当前使用的GPU设备。这里设置为1号GPU设备（第二块显卡）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA support \n",
    "\n",
    "#设置pytorch的设备，代表了在哪里执行张量积算，设备可以是cpu或者cuda（gpu），并将这个做运算的设备对象存储在变量device中，后续张量计算回在这个设备上执行\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Physics-informed Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# the deep neural network\n",
    "class DNN(torch.nn.Module):\n",
    "    #第一个方法\n",
    "    def __init__(self, layers,gamma,num_of_GP): #初始化函数，layers是一个列表，表示每一层的神经元个数，gamma是GP的参数，num_of_GP是GP的参数\n",
    "        super(DNN, self).__init__() #调用父类的__init__方法进行初始化\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1 #定义名为depth的属性，表示神经网络的深度，等于层数-1\n",
    "        self.num_of_GP = num_of_GP #定义名为num_of_GP的属性，表示GP的参数\n",
    "        self.gamma = gamma #定义名为gamma的属性，表示GP的参数\n",
    "        \n",
    "        # set up layer order dict\n",
    "        self.activation = torch.nn.Tanh #设置激活函数为tanh\n",
    "         \n",
    "        layer_list = list() #定义一个空列表layer_list\n",
    "        for i in range(self.depth - 1):  #循环depth次\n",
    "            #将每一层（全连接层）添加到layer_list中\n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            #将每一层的激活函数添加到layer_list中\n",
    "            layer_list.append(('activation_%d' % i, self.activation()))\n",
    "\n",
    "        #循环结束后，将最后一层的线性变换添加到layer_list中（因为没有激活函数了）\n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(self.num_of_GP, layers[-1], bias=False))\n",
    "        )\n",
    "        #然后使用OrderedDict将layer_list中的元素转换为有序字典\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers，将layerDict转换为一个神经网络模型，赋值给self.layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "    \n",
    "\n",
    "        # Initialize weights\n",
    "        self._initialize_weights()  \n",
    "\n",
    "        # # Initialize beta for the output layer\n",
    "        # self.beta = torch.nn.Parameter(torch.randn(layers[-1], 1))  # 初始化回归权重矩阵beta\n",
    "\n",
    "        # Initialize GP_W and GP_b\n",
    "        self.GP_W = torch.randn(layers[-2], self.num_of_GP) * math.sqrt(2 * self.gamma)  # 初始化GP_W\n",
    "        self.GP_b = torch.rand(1, self.num_of_GP) * 2 * math.pi  # 初始化GP_b\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for idx, m in enumerate(self.layers): #遍历神经网络模型的每一层，获取每一层的索引idx和层对象m(注意这里idx会包括激活函数，也占一个idx)\n",
    "            if isinstance(m, torch.nn.Linear): #判断层对象m是否是全连接层\n",
    "\n",
    "                # 自定义初始化函数\n",
    "                fan_in = m.weight.size(0)  # 输入单元数量\n",
    "                fan_out = m.weight.size(1)  # 输出单元数量\n",
    "                std = (2 / (fan_in + fan_out)) ** 0.5  # 计算标准差\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    m.weight.normal_(0, std)  # 使用自定义标准差初始化权重\n",
    "                if m.bias is not None: #若存在偏置\n",
    "                    torch.nn.init.zeros_(m.bias) #使用常数初始化方法初始化偏置，初始化为0\n",
    "                \n",
    "                # 归一化权重\n",
    "                if idx > 0 and idx < len(self.layers) - 2: #不归一化输入层、输出层和最后一个隐藏层\n",
    "                #注意这里其实idx包含了激活函数，例如对于[1,50,50,50,50,1]，这里共有6层，但是idx应该是9，因为四个隐藏层+四个激活函数+输出层。所以因为idx0是全连接层，最后一个idx为输出层，因此这样做是可以剔除第一个权重和最后一个权重的\n",
    "                    with torch.no_grad(): #确保归一化过程中不进行梯度计算\n",
    "                        norm = m.weight.norm(2) #计算该层权重的二范数\n",
    "                        if norm > 0.99: #若二范数大于0.99\n",
    "                            m.weight.mul_(0.99 / norm) #将权重乘以0.99/norm，使得二范数等于0.99\n",
    "    \n",
    "    #第二个方法，前向传播\n",
    "    def forward(self, X, lb, ub):  # 接收输入x\n",
    "        device = X.device  # 获取输入张量的设备\n",
    "        self.GP_W = self.GP_W.to(device)  # 将GP_W移动到相同设备\n",
    "        self.GP_b = self.GP_b.to(device)  # 将GP_b移动到相同设备\n",
    "        H = 2.0*(X - lb)/(ub - lb) - 1.0 #这里H是X经过归一化处理后的结果，将X映射到了[-1,1]区间内\n",
    "        #第一层\n",
    "        H = self.layers[0](H)\n",
    "        H = self.layers[1](H)\n",
    "\n",
    "        # 中间隐藏层\n",
    "        for i in range(2, len(self.layers) - 2, 2):  # 循环遍历中间隐藏层\n",
    "            with torch.no_grad():\n",
    "                norm = self.layers[i].weight.norm(2)\n",
    "                if norm > 0.99:\n",
    "                    self.layers[i].weight.mul_(0.99 / norm)\n",
    "            # H = self.layers[i+1](self.layers[i](H))\n",
    "            H_1 = self.layers[i+1](self.layers[i](H))  # 计算输出并加上偏置(i+1是激活函数，i是全连接层)\n",
    "            # H = H + H_1  # 加上前一层的输出构成本层新的输出\n",
    "            # H = H.clone() + H_1\n",
    "\n",
    "        # 在最后一个隐藏层和输出层之间添加一层\n",
    "        H1 = torch.matmul(H, self.GP_W) + self.GP_b  # 计算H1\n",
    "        Fai = math.sqrt(2 / self.num_of_GP) * torch.cos(H1)  # 计算Fai\n",
    "        H = Fai  # 更新H为Fai\n",
    "\n",
    "        # 输出层\n",
    "        out = self.layers[-1](H)  # 计算输出\n",
    "        return out  # 返回输出out\n",
    "    \n",
    "    #第三个方法，获取hidden输出\n",
    "    def dnn_for_hidden_features(self, X, lb, ub):  # 接收输入x\n",
    "        H = 2.0*(X - lb)/(ub - lb) - 1.0 #这里H是X经过归一化处理后的结果，将X映射到了[-1,1]区间内\n",
    "        #第一层\n",
    "        H = self.layers[0](H)\n",
    "        H = self.layers[1](H)\n",
    "\n",
    "        # 中间隐藏层\n",
    "        for i in range(2, len(self.layers) - 2, 2):  # 循环遍历中间隐藏层\n",
    "            with torch.no_grad():\n",
    "                norm = self.layers[i].weight.norm(2)\n",
    "                if norm > 0.99:\n",
    "                    self.layers[i].weight.mul_(0.99 / norm)\n",
    "            # H = self.layers[i+1](self.layers[i](H))\n",
    "            H_1 = self.layers[i+1](self.layers[i](H))  # 计算输出并加上偏置(i+1是激活函数，i是全连接层)\n",
    "            # H = H + H_1  # 加上前一层的输出构成本层新的输出\n",
    "            # H = H.clone() + H_1 # 加上前一层的输出构成本层新的输出\n",
    "\n",
    "        # 在最后一个隐藏层和输出层之间添加一层\n",
    "        H1 = torch.matmul(H, self.GP_W) + self.GP_b  # 计算H1\n",
    "        Fai = math.sqrt(2 / self.num_of_GP) * torch.cos(H1)  # 计算Fai\n",
    "\n",
    "        return H, Fai  # 返回输出out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the physics-guided neural network\n",
    "class PhysicsInformedNN():\n",
    "    # Initialize the class\n",
    "    def __init__(self,X_f, X_bound, layers, lb, ub, gamma, num_of_GP): #这个类包含的第一个方法__init__，这是一个特殊的方法，也就是这个类的构造函数，用于初始化新创建的对象，接受了几个参数\n",
    "    \n",
    "        self.gamma = gamma\n",
    "        self.num_of_GP = num_of_GP\n",
    "\n",
    "        self.X_f = torch.tensor(X_f, requires_grad=True).float().to(device) #配位点\n",
    "        self.X_bound = torch.tensor(X_bound, requires_grad=True).float().to(device) #边界点\n",
    "\n",
    "        self.lb = torch.tensor(lb).float().to(device) #下界\n",
    "        self.ub = torch.tensor(ub).float().to(device) #上界\n",
    "        \n",
    "        self.layers = layers\n",
    "        \n",
    "        # deep neural networks\n",
    "        self.dnn = DNN(layers,gamma,num_of_GP).to(device) #创建一个DNN类的实例，传入layers参数来实现神经网络的初始化，然后将这个实例移动到指定的设备上\n",
    "        \n",
    "        \n",
    "        # optimizers: using the same settings\n",
    "        #创建优化器optimizer，使用LBFGS算法，具体每个参数意义见下方\n",
    "        self.optimizer_LBFGS = torch.optim.LBFGS(\n",
    "            self.dnn.parameters(), #要优化的参数，这里返回的是一个生成器，包含了self.dnn中的所有参数（神经网络权重与偏置）\n",
    "            lr=1.0,  #学习率设置为1\n",
    "            max_iter=50000,  #最大迭代次数为50000\n",
    "            max_eval=50000,  #最大评估次数为50000\n",
    "            history_size=50, #历史大小为50，即用于计算Hessian矩阵近似的最近几步的信息\n",
    "            tolerance_grad=1e-5,  #优化的第一个停止条件，当梯度的L2范数小于1e-5时停止优化\n",
    "            tolerance_change=1.0 * np.finfo(float).eps, #优化的第二个停止条件，当优化的目标函数值的变化小于1.0 * np.finfo(float).eps时停止优化\n",
    "            line_search_fn=\"strong_wolfe\"       # 制定了用于一维搜索的方法，这里表示用强Wolfe条件\n",
    "        )\n",
    "\n",
    "        #创建第二个优化器，括号内为要优化的参数，使用Adam优化方法\n",
    "        self.optimizer_Adam = torch.optim.Adam(self.dnn.parameters())\n",
    "\n",
    "        self.iter = 0 #记录迭代次数 \n",
    "        \n",
    "    #定义了一个名为net_u的函数/方法，用于计算神经网络的输出。这个方法接受两个参数，分别是x和t，其中x是输入数据，t是时间数据。最后返回神经网络的输出。     \n",
    "    def net_u(self, X):  \n",
    "        u = self.dnn(X,self.lb,self.ub)  #（第一个参数将输入的两个参数x和t在第二个维度（列）上进行拼接，形成一个新的张量）调用DNN，根据两个参数权重和偏置，以及新得到的张量，计算神经网络的输出u\n",
    "        return u\n",
    "\n",
    "    \n",
    "    #定义了一个名为net_f的函数/方法，用于计算论文中的f。这个方法接受两个参数，分别是x和t，其中x是输入数据，t是时间数据。最后返回计算得到的f。\n",
    "    def net_f(self, x):\n",
    "        \"\"\" The pytorch autograd version of calculating residual \"\"\"\n",
    "        u = self.net_u(x) #调用上面的net_u函数，计算神经网络的输出u\n",
    "        \n",
    "        u_x = torch.autograd.grad(\n",
    "            u, x, \n",
    "            grad_outputs=torch.ones_like(u),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        u_xx = torch.autograd.grad(\n",
    "            u_x, x, \n",
    "            grad_outputs=torch.ones_like(u_x),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        PI = np.pi #获取π的值\n",
    "        fx = -1*PI**2*torch.sin(PI*x)-PI*torch.cos(PI*x)*(torch.sin(PI*x))**2 #计算f(x)的值\n",
    "        m_loss =  u_xx-u**2 *u_x -fx #计算损失函数\n",
    "        \n",
    "        return m_loss #返回损失函数\n",
    "\n",
    "    # def net_f_u(self,x):\n",
    "    #     u = self.net_u(x) #调用上面的net_u函数，计算神经网络的输出u\n",
    "        \n",
    "    #     #计算u关于t的梯度，也就是u关于t的导数，这里使用了pytorch的自动求导功能\n",
    "    #     u_x = torch.autograd.grad(\n",
    "    #         u, x,  #输入的张量，要计算u关于t的导数\n",
    "    #         grad_outputs=torch.ones_like(u), #生成一个与u形状相同，所有元素均为1的张量，这个参数用于指定向量-雅可比积的像两部分\n",
    "    #         retain_graph=True, #表示计算完梯度之后保留计算图若需要多次计算梯度，则需要设置改参数为True\n",
    "    #         create_graph=True #创建梯度的计算图，使我们能够计算高阶导数\n",
    "    #     )[0] #这个函数的返回值是一个元组，其中包含了每个输入张量的梯度。这里只关心第一个输入张量u的梯度，所以我们使用[0]来获取这个梯度。？？？？又说只有一个梯度\n",
    "\n",
    "    #     PI = np.pi\n",
    "    #     u_xx = torch.autograd.grad(\n",
    "    #         u_x, x, \n",
    "    #         grad_outputs=torch.ones_like(u_x),\n",
    "    #         retain_graph=True,\n",
    "    #         create_graph=True\n",
    "    #     )[0]\n",
    "\n",
    "    #     fx = -1*PI**2*torch.sin(PI*x)-PI*torch.cos(PI*x)*(torch.sin(PI*x))**2 #计算f(x)的值\n",
    "    #     m_loss =  u_xx-u**2 *u_x -fx #计算损失函数\n",
    "        \n",
    "    #     return m_loss #返回损失函数\n",
    "\n",
    "\n",
    "    \n",
    "    def loss_func(self):\n",
    "        self.optimizer_LBFGS.zero_grad() #清除之前计算的梯度（在PyTorch中，梯度会累积，所以在每次新的优化迭代之前，我们需要清除之前的梯度）\n",
    "        \n",
    "        u_pred = self.net_u(self.X_f) #调用之前定义的函数，传入参数得到神经网络的输出u\n",
    "        u_pred_bound = self.net_u(self.X_bound) #调用之前定义的函数，传入参数得到神经网络的输出u\n",
    "        f_pred = self.net_f(self.X_f) #调用之前定义的函数，传入参数计算得到f\n",
    "    \n",
    "\n",
    "\n",
    "        loss = 1*torch.mean((self.u_pred_bound) ** 2) + \\\n",
    "                torch.mean(f_pred ** 2) #计算损失函数\n",
    "        \n",
    "        loss.backward() #被调用以计算损失函数关于神经网络参数的梯度。这个梯度将被用于优化器来更新神经网络参数\n",
    "        self.iter += 1 #每调用一次损失函数，迭代次数加1\n",
    "        if self.iter % 100 == 0:\n",
    "            print(\n",
    "                'Iter %d, Loss: %.5e' % (self.iter, loss.item()) \n",
    "            ) #每100次迭代，打印一次迭代次数、总的loss、loss_u和loss_f\n",
    "        return loss #返回总的loss\n",
    "    \n",
    "    # def train(self, nIter, nIterLBFGS):\n",
    "    def train(self, nIter):\n",
    "        self.dnn.train() #将神经网络设置为训练模式而不是评估模式\n",
    "        \n",
    "        # # 初始化一个列表来存储每个epoch的权重矩阵\n",
    "        # self.weights = []   \n",
    "\n",
    "        #使用Adam优化器优化nIter次\n",
    "        # for epoch in tqdm(range(nIter), desc='Adam'):\n",
    "        for epoch in range(nIter):\n",
    "            u_pred = self.net_u(self.X_f) #调用之前定义的函数，传入参数得到神经网络的输出u\n",
    "            u_pred_bound = self.net_u(self.X_bound) #调用之前定义的函数，传入参数得到神经网络的输出u\n",
    "            f_pred = self.net_f(self.X_f) #调用之前定义的函数，传入参数计算得到f\n",
    "        \n",
    "\n",
    "\n",
    "            loss = 1*torch.mean((u_pred_bound) ** 2) + \\\n",
    "                   torch.mean(f_pred ** 2) #计算损失函数\n",
    "            \n",
    "            # Backward and optimize\n",
    "            self.optimizer_Adam.zero_grad() #清除该优化器之前计算的梯度（在PyTorch中，梯度会累积，所以在每次新的优化迭代之前，我们需要清除之前的梯度）\n",
    "            loss.backward() #被调用以计算损失函数关于神经网络参数的梯度。这个梯度将被用于优化器来更新神经网络参数\n",
    "            self.optimizer_Adam.step()  #使用之前的优化器self.optimizer_Adam，调用step方法(执行一步优化算法)，传入损失函数self.loss_func，进行优化\n",
    "            \n",
    "            # #record the loss value\n",
    "            # self.loss_value.append(loss) #将计算得到的loss值添加到self.loss_value列表中\n",
    "\n",
    "            # # record the test error\n",
    "            # with torch.no_grad():\n",
    "            #     u_real_pred = self.net_u(self.x_star, self.t_star) #调用之前定义的函数，传入参数得到神经网络的输出u\n",
    "\n",
    "\n",
    "            # error_test = torch.norm(self.u_star-u_real_pred,2)/torch.norm(self.u_star,2)\n",
    "\n",
    "            # self.test_error.append(error_test)\n",
    "\n",
    "            # # 记录每一层的权重矩阵\n",
    "            # epoch_weights = []\n",
    "            # for layer in self.dnn.layers:\n",
    "            #     if isinstance(layer, torch.nn.Linear):  # 检查是否为全连接层\n",
    "            #         epoch_weights.append(layer.weight.data.clone())  # 使用.clone()来获取权重的副本\n",
    "            # self.weights.append(epoch_weights)\n",
    "\n",
    "            # W = self.weights\n",
    "\n",
    "            # for i in tqdm(range(1), desc='LBFGS'):\n",
    "            #     self.optimizer_LBFGS.step(self.loss_func)\n",
    "\n",
    "            \n",
    "    def predict(self, X):\n",
    "        x = torch.tensor(X, requires_grad=True).float().to(device) #从输入中得到x和t（第一列和第二列），是张量，需要计算梯度，转换为浮点数类型，并将张量移动到指定设备上\n",
    "\n",
    "        self.dnn.eval() #将神经网络切换为评估模式\n",
    "        u = self.net_u(x) #调用之前定义的函数得到神经网络的输出u,以及f\n",
    "        f = self.net_f(x)\n",
    "        u = u.detach().cpu().numpy() #将张量u和f先从计算图中分离出来，然后转换为numpy数组，最后将这个数组移动到cpu上\n",
    "        f = f.detach().cpu().numpy()\n",
    "        return u, f\n",
    "    \n",
    "    \n",
    "    def net_for_hidden_features(self, X):\n",
    "        self.dnn.eval() #将神经网络切换为评估模式\n",
    "        # x = torch.tensor(X[:, 0:1], requires_grad=True).float().to(device)\n",
    "        X = torch.tensor(X, requires_grad=True).float().to(device)\n",
    "        H,Fai = self.dnn.dnn_for_hidden_features(X, self.lb, self.ub)\n",
    "        H = H.detach().cpu().numpy()\n",
    "        Fai = Fai.detach().cpu().numpy()\n",
    "        return H,Fai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # def hidden_predict(self, x,t):\n",
    "    #     x = torch.tensor(x, requires_grad=True).float().to(device) #从输入中得到x和t（第一列和第二列），是张量，需要计算梯度，转换为浮点数类型，并将张量移动到指定设备上\n",
    "    #     t = torch.tensor(t, requires_grad=True).float().to(device)\n",
    "    #     self.dnn.eval()\n",
    "    #     hidden_output = self.dnn.hidden_output(torch.cat([x, t], dim=1))\n",
    "    #     hidden_output_x = hidden_output[:, 0]\n",
    "    #     hidden_output_t = hidden_output[:, 1]\n",
    "    #     hidden_output_x = hidden_output_x.detach().cpu().numpy()\n",
    "    #     hidden_output_t = hidden_output_t.detach().cpu().numpy()\n",
    "    #     return hidden_output_x, hidden_output_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 20.3840\n"
     ]
    }
   ],
   "source": [
    "noise = 0.0        \n",
    "\n",
    "# Doman bounds\n",
    "lb = np.array([-1.0])\n",
    "ub = np.array([1.0])\n",
    "X_bound = np.array([[-1.0],[1.0]] )\n",
    "\n",
    "N0 = 50\n",
    "N_b = 50\n",
    "N_f = 10\n",
    "gamma = 5.0\n",
    "num_of_GP = 1024\n",
    "\n",
    "layers = [1, 100, 100,1]\n",
    "\n",
    "x_t = np.linspace(-1,1,100) #从-1到1生成100个数,形状为(100,)\n",
    "X_f = lb + (ub-lb)*lhs(1, N_f) #生成N_f个[lb,ub]之间的随机数，形状为(N_f,1)\n",
    "\n",
    "#这段代码的目的是将X_f中的每个数替换为x_t中与其差的绝对值最小的那个数，即确保X_f中的点与x_t中的点尽可能对齐\n",
    "for l in range(X_f.shape[0]): #遍历X_f的每一行，即总共N_f行\n",
    "    temp_1 = X_f[l] #取出X_f的第l个数\n",
    "    temp_2 = np.abs(temp_1 - x_t) #计算temp_1（即X_f的第l个数）与x_t中每个点的差的绝对值\n",
    "    inx = np.argmin(temp_2) #返回temp_2中最小值的索引，即X_f的第l个数与x_t中每个点的差的绝对值最小的那个点的索引\n",
    "    X_f[l] = x_t[inx] #将X_f的第l个数替换为x_t中与其差的绝对值最小的那个点\n",
    "\n",
    "model = PhysicsInformedNN(X_f,X_bound, layers, lb, ub,gamma, num_of_GP)  #创建PINN模型并输入各种参数   \n",
    "#获取当前时间并赋值给start_time \n",
    "start_time = time.time()     \n",
    "#开始训练模型           \n",
    "model.train(5000)\n",
    "#训练结束后获取当前时间并减去start_time，得到训练时间并赋值给elapsed\n",
    "elapsed = time.time() - start_time                \n",
    "#打印训练时间\n",
    "print('Training time: %.4f' % (elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = np.array([-1.0])\n",
    "lb = np.reshape(lb,[1,1]) #将lb变为形状为(1,1)\n",
    "ub = np.array([1.0])\n",
    "ub = np.reshape(ub,[1,1])\n",
    "X_know = np.concatenate((lb,ub,X_f),0) #known point,将lb、ub和X_f按行(第一个维度)拼接在一起，形状为(N_f+2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_pred= model.predict(X_know)  #预测\n",
    "f_know = u_pred #X_know的预测值即为f_know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t =np.reshape(x_t,[x_t.shape[0],1]) #将x_t变为形状为(100,1)，其中100来自于x_t的长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hidden_pred_small, Fai_pred_small = model.net_for_hidden_features(X_know)\n",
    "X = Hidden_pred_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hidden_pred_all, Fai_pred_all = model.net_for_hidden_features(x_t)\n",
    "X_xing = Hidden_pred_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_xing = X_xing.shape[0]\n",
    "Cov_xing_xing = np.zeros(shape=(n_xing,n_xing), dtype=float)\n",
    "for i in range(n_xing):\n",
    "    for j in range(n_xing):\n",
    "        xi = X_xing[i:i+1,:]\n",
    "        xj = X_xing[j:j+1,:]\n",
    "        dij = np.sum((xi-xj)**2)\n",
    "        Cov_xing_xing[i][j] = np.exp(-gamma*dij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X.shape[0]\n",
    "Cov_X_X = np.zeros(shape=(n,n), dtype=float)\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        xi = X[i:i+1,:]\n",
    "        xj = X[j:j+1,:]\n",
    "        dij = np.sum((xi-xj)**2)\n",
    "        Cov_X_X[i][j] = np.exp(-gamma*dij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cov_xing_X = np.zeros(shape=(n_xing,n), dtype=float)\n",
    "for i in range(n_xing):\n",
    "    for j in range(n):\n",
    "        xi = X_xing[i:i+1,:]\n",
    "        xj = X[j:j+1,:]\n",
    "        dij = np.sum((xi-xj)**2)\n",
    "        Cov_xing_X[i][j] = np.exp(-gamma*dij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cov_X_xing = Cov_xing_X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_orig = Cov_X_X\n",
    "xishu = 100000000\n",
    "rho = rho_orig*xishu \n",
    "u, s, v = np.linalg.svd(rho)\n",
    "inv_s=np.linalg.inv(np.diag(s))\n",
    "t1= np.matmul(v.T, inv_s) \n",
    "t2= np.matmul(t1, u.T)\n",
    "t3= np.matmul(t2, rho) # Check whether the obtained inverse matrix is correct. If it is the identity matrix, it means there is no problem.\n",
    "inv_rho = t2*xishu  # Inverse of covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_2= Cov_xing_xing - np.matmul(np.matmul(Cov_xing_X, inv_rho), Cov_X_xing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_2 = np.diag(sigma_2)\n",
    "sigma_2 = np.abs(sigma_2)\n",
    "sigma = np.sqrt(sigma_2)\n",
    "sigma = sigma[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "PI = np.pi\n",
    "reall = np.sin(PI*x_t) # Ground truth\n",
    "prediction= model.predict(x_t)  #  prediction for all points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 1)\n",
      "(100, 1)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_know\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(x_t\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mprediction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[0;32m      4\u001b[0m       )\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(prediction))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(reall\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print(X_know.shape)\n",
    "print(x_t.shape)\n",
    "print(prediction.shape\n",
    "      )\n",
    "print(len(prediction))\n",
    "print(reall.shape)\n",
    "print(len(reall))\n",
    "print(x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (100, 1) and (2, 100, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(x_t,reall,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(x_t,prediction\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39msigma,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(X_know[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m],f_know[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\lcy\\anaconda3\\envs\\pytorchgpu\\lib\\site-packages\\matplotlib\\pyplot.py:3590\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3582\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   3583\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[0;32m   3584\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3588\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3589\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[1;32m-> 3590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[0;32m   3591\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m   3592\u001b[0m         scalex\u001b[38;5;241m=\u001b[39mscalex,\n\u001b[0;32m   3593\u001b[0m         scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[0;32m   3594\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[0;32m   3595\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3596\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\lcy\\anaconda3\\envs\\pytorchgpu\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1724\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1481\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1482\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1483\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1721\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1722\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1723\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1724\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1725\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1726\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mc:\\Users\\lcy\\anaconda3\\envs\\pytorchgpu\\lib\\site-packages\\matplotlib\\axes\\_base.py:303\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    301\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    302\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 303\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lcy\\anaconda3\\envs\\pytorchgpu\\lib\\site-packages\\matplotlib\\axes\\_base.py:499\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    496\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 499\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    500\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    503\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (100, 1) and (2, 100, 1)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "plt.style.use('default')\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(x_t,reall,'k')\n",
    "plt.plot(x_t,prediction,'r')\n",
    "plt.plot(x_t,prediction+3*sigma,'b')\n",
    "plt.scatter(X_know[0:2],f_know[0:2])\n",
    "plt.scatter(X_know[2:-1],f_know[2:-1])\n",
    "\n",
    "plt.legend([ 'Ground truth','Prediction','Prediction bounds','Boundary points','Collocation points'], loc = 'best') \n",
    "plt.plot(x_t,prediction-3*sigma,'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
